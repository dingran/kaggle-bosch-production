Filename: explore2.py

Line #    Mem usage    Increment   Line Contents
================================================
   230    170.7 MiB      0.0 MiB   @profile(stream=f_mem)
   231                             def main(run_info_fname=None,
   232                                      N_start=None,
   233                                      N_files_train=10,
   234                                      N_files_test=10,
   235                                      cv=False,
   236                                      # if True running cross validation if False, run single model training session and importance analysis
   237                                      feature_down_select=False,
   238                                      analyze_feature_importance=False,
   239                                      early_stop_rounds=10
   240                                      ):
   241    170.7 MiB      0.0 MiB       datetime_str = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
   242                             
   243    170.7 MiB      0.0 MiB       if run_info_fname is None:
   244    170.7 MiB      0.0 MiB           run_info = dict()
   245    170.7 MiB      0.0 MiB           N_splits = ub.N_split
   246    170.7 MiB      0.0 MiB           if N_files_train > N_splits:
   247                                         N_files_train = N_splits
   248    170.7 MiB      0.0 MiB           if N_files_test > N_splits:
   249                                         N_files_test = N_splits
   250                             
   251    170.7 MiB      0.0 MiB           do_filtering = False
   252                             
   253    170.7 MiB      0.0 MiB           if analyze_feature_importance:
   254    170.7 MiB      0.0 MiB               do_filtering = False
   255                             
   256    170.7 MiB      0.0 MiB           if feature_down_select:
   257                                         do_filtering = False
   258                                         analyze_feature_importance = False
   259                             
   260    170.7 MiB      0.0 MiB           run_info['N_splits'] = N_splits
   261    170.7 MiB      0.0 MiB           run_info['N_files_train'] = N_files_train
   262    170.7 MiB      0.0 MiB           run_info['N_files_test'] = N_files_test
   263    170.7 MiB      0.0 MiB           run_info['do_filtering'] = do_filtering
   264    170.7 MiB      0.0 MiB           run_info['feature_down_select'] = feature_down_select
   265    170.7 MiB      0.0 MiB           run_info['cv'] = cv
   266    170.7 MiB      0.0 MiB           run_info['analyze_feature_importance'] = analyze_feature_importance
   267    170.7 MiB      0.0 MiB           run_info['early_stop_rounds'] = early_stop_rounds
   268                             
   269    170.7 MiB      0.0 MiB           df_train, n_start = load_data(load_test=False, N_start=N_start, N_read=N_files_train, N_split=N_splits,
   270    170.7 MiB      0.0 MiB                                         shuffle=False,
   271  16614.5 MiB  16443.9 MiB                                         filter=do_filtering)
   272  16614.5 MiB      0.0 MiB           df_test, _ = load_data(load_test=True, N_start=n_start, N_read=N_files_test, N_split=N_splits, shuffle=False,
   273  34430.7 MiB  17816.1 MiB                                  filter=do_filtering)
   274                             
   275  34430.7 MiB      0.0 MiB           ub.log('generating id diff columns based on various dates columns')
   276  34430.7 MiB      0.0 MiB           dates_cols = [x for x in list(df_train.columns) if 'start_date' in x or 'end_date' in x]
   277                             
   278                                     # print dates_cols
   279                             
   280  44517.4 MiB  10086.7 MiB           df_datesort = pd.concat([df_train[['Id'] + dates_cols], df_test[['Id'] + dates_cols]],
   281  45083.5 MiB    566.1 MiB                                   ignore_index=True)
   282  45083.5 MiB      0.0 MiB           gc.collect()
   283                             
   284  56918.0 MiB  11834.5 MiB           for c in dates_cols:
   285  55791.4 MiB  -1126.6 MiB               df_datesort.sort_values(by=[c, 'Id'], inplace=True)
   286  55791.4 MiB      0.0 MiB               df_datesort[c + '_id_diff'] = df_datesort['Id'].diff().fillna(999999).astype(int)
   287  55791.4 MiB      0.0 MiB               df_datesort[c + '_id_diff_reverse'] = df_datesort['Id'].iloc[::-1].diff().fillna(999999).astype(int)
   288                             
   289  56918.0 MiB   1126.6 MiB               df_datesort.drop([c], axis=1, inplace=True)
   290                             
   291  47374.4 MiB  -9543.6 MiB           df_datesort.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_datesort_debug.csv'))
   292                             
   293  45654.7 MiB  -1719.7 MiB           gc.collect()
   294  54461.3 MiB   8806.6 MiB           df_train = df_train.merge(df_datesort, on='Id')
   295  54461.5 MiB      0.2 MiB           df_train.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_train_debug.csv'))
   296                             
   297  42405.1 MiB -12056.4 MiB           gc.collect()
   298  52955.4 MiB  10550.3 MiB           df_test = df_test.merge(df_datesort, on='Id')
   299  52955.4 MiB      0.0 MiB           df_test.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_test_debug.csv'))
   300                             
   301  46734.7 MiB  -6220.7 MiB           df_test['Response'] = 0
   302                             
   303  46734.7 MiB      0.0 MiB           print df_train.shape
   304  46734.7 MiB      0.0 MiB           print df_test.shape
   305  37559.6 MiB  -9175.2 MiB           gc.collect()
   306                             
   307  37559.6 MiB      0.0 MiB           if N_files_train == N_splits:
   308                                         split_data(df_train,
   309                                                    output_fname_template=os.path.join(ub.processed_data_dir, 'df_train_preprocessed_part{}.csv'))
   310  37559.6 MiB      0.0 MiB           if N_files_test == N_splits:
   311                                         split_data(df_test,
   312                                                    output_fname_template=os.path.join(ub.processed_data_dir, 'df_test_preprocessed_part{}.csv'))
   313                             
   314  37559.6 MiB      0.0 MiB           fillna = True
   315  37559.6 MiB      0.0 MiB           run_info['fillna'] = fillna
   316  37559.6 MiB      0.0 MiB           if fillna:
   317  37559.6 MiB      0.0 MiB               ub.log('Filling na...')
   318  42214.9 MiB   4655.3 MiB               for df in [df_train, df_test]:
   319  43370.1 MiB   1155.1 MiB                   cols_full_flag = df.isnull().any()
   320  43370.1 MiB      0.0 MiB                   non_full_cols = list(cols_full_flag[cols_full_flag].index)
   321  43370.1 MiB      0.0 MiB                   print 'Non-full columns: {}'.format(len(non_full_cols))
   322                                             # print non_full_cols
   323                             
   324                                             if 1:
   325  43374.9 MiB      4.9 MiB                       df.fillna(-999999, inplace=True)
   326                                             else:
   327                                                 # print df.PersonalField7.unique()
   328                                                 for c in non_full_cols:
   329                                                     if len(df[c].unique()) > 2:
   330                                                         most_frequent_items = df[c].value_counts().idxmax()
   331                                                         print c, most_frequent_items
   332                                                         df[c].fillna(value=most_frequent_items, inplace=True)
   333                                                     else:  # if it is only a pair of value [somthing, nan] then fill in "missing"
   334                                                         df[c].fillna(value='missing', inplace=True)
   335                                                         print c, df[c].unique()
   336                             
   337  43374.9 MiB      0.0 MiB                   cols_full_flag = df.isnull().any()
   338  43374.9 MiB      0.0 MiB                   non_full_cols = list(cols_full_flag[cols_full_flag].index)
   339  43374.9 MiB      0.0 MiB                   print 'Non-full columns: {}'.format(len(non_full_cols))
   340                             
   341  43374.9 MiB      0.0 MiB                   le = LabelEncoder()
   342  43375.3 MiB      0.4 MiB                   obj_cols = df.select_dtypes(include=['object']).columns
   343                                             # print 'Obj columns: ', list(obj_cols)
   344  43375.3 MiB      0.0 MiB                   for col in obj_cols:
   345  43372.9 MiB     -2.4 MiB                       df[col] = le.fit_transform(df[col])
   346                             
   347  37432.7 MiB  -5940.2 MiB               df_train.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_train_cleanup_debug.csv'))
   348  37435.7 MiB      3.0 MiB               df_test.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_train_cleanup_debug.csv'))
   349                             
   350  37435.7 MiB      0.0 MiB           ub.log('Dropping Id and Response columns...')
   351  37435.7 MiB      0.0 MiB           columns_to_drop = ['Id', 'Response']
   352  41911.2 MiB   4475.5 MiB           shuffle_col = df_train[['Id']].copy()
   353  41911.2 MiB      0.0 MiB           shuffle_col['Id'] = np.random.randn(len(shuffle_col))
   354                             
   355  41911.2 MiB      0.0 MiB           y_total_df = df_train['Response']
   356  41911.2 MiB      0.0 MiB           y_total = df_train['Response'].values
   357  47187.9 MiB   5276.7 MiB           df_train.drop(columns_to_drop, axis=1, inplace=True)
   358  48946.1 MiB   1758.3 MiB           df_test.drop(columns_to_drop, axis=1, inplace=True)
   359                             
   360  48946.1 MiB      0.0 MiB           print df_train.shape
   361  48946.1 MiB      0.0 MiB           print df_test.shape
   362  48946.1 MiB      0.0 MiB           prior = np.sum(y_total) / (1. * len(y_total))
   363  48946.4 MiB      0.3 MiB           print 'prior: {}'.format(prior)
   364  48946.4 MiB      0.0 MiB           run_info['prior'] = prior
   365  50042.7 MiB   1096.2 MiB           gc.collect()
   366                             
   367  50042.7 MiB      0.0 MiB           feature_imp_fname_tmplate = os.path.join(ub.output_dir, 'feature_importance_xgb_{}')
   368  50042.7 MiB      0.0 MiB           top_features_fname = feature_imp_fname_tmplate.format('accumu_list.txt')
   369  50042.7 MiB      0.0 MiB           if feature_down_select:
   370                                         ub.log('Feature down selected based on {}...'.format(top_features_fname))
   371                                         #todo may need to set a maxN for the number of features to use
   372                                         
   373                                         with open(top_features_fname, 'r') as tf:
   374                                             selected_cols = [x.strip() for x in tf.readlines()]
   375                                         df_train = df_train[selected_cols]
   376                                         df_test = df_test[selected_cols]
   377                                         print df_train.shape
   378                                         print df_test.shape
   379                                         print df_train.columns
   380                             
   381  50042.7 MiB      0.0 MiB           feature_names = list(df_train.columns)
   382                             
   383  50042.7 MiB      0.0 MiB           postfix_train = '{}_{}of{}'.format(datetime_str, N_files_train, N_splits)
   384  50042.7 MiB      0.0 MiB           postfix_test = '{}_{}of{}'.format(datetime_str, N_files_test, N_splits)
   385                             
   386  50042.7 MiB      0.0 MiB           run_info['postfix_train'] = postfix_train
   387  50042.7 MiB      0.0 MiB           run_info['postfix_test'] = postfix_test
   388                             
   389  50042.7 MiB      0.0 MiB           testsize = 0.3
   390  50042.7 MiB      0.0 MiB           run_info['testsize'] = testsize
   391                             
   392  50042.7 MiB      0.0 MiB           train_test_split_method = 1
   393                             
   394  50042.7 MiB      0.0 MiB           ub.log('Train/val split using testsize={}, split_method={}'.format(testsize, train_test_split_method))
   395  50042.7 MiB      0.0 MiB           if train_test_split_method == 1:
   396  50045.9 MiB      3.2 MiB               train_idx = shuffle_col[shuffle_col['Id'] > testsize].index
   397  50045.9 MiB      0.0 MiB               val_idx = shuffle_col[shuffle_col['Id'] <= testsize].index
   398  50045.9 MiB      0.0 MiB               ub.log('Done shuffling...')
   399  50045.9 MiB      0.0 MiB               print 'len of train_idx', len(train_idx)
   400  50045.9 MiB      0.0 MiB               print 'len of val_idx', len(val_idx)
   401  50045.9 MiB      0.0 MiB               y_train = y_total_df.loc[train_idx].values
   402  50045.9 MiB      0.0 MiB               y_val = y_total_df.loc[val_idx].values
   403                             
   404  51077.2 MiB   1031.3 MiB               xgtrain = xgb.DMatrix(df_train.loc[train_idx].values, y_train, feature_names=feature_names)
   405  51077.6 MiB      0.4 MiB               ub.log('Assembled xgtrain')
   406  49319.8 MiB  -1757.8 MiB               xgval = xgb.DMatrix(df_train.loc[val_idx].values, y_val, feature_names=feature_names)
   407  49319.9 MiB      0.1 MiB               ub.log('Assembled xgval')
   408  49319.9 MiB      0.0 MiB               del df_train
   409  49319.9 MiB      0.0 MiB               ub.log('Deleted df_train')
   410  36758.7 MiB -12561.2 MiB               gc.collect()
   411                                     else:
   412                                         x_train, x_val, y_train, y_val = train_test_split(df_train.values, y_total, test_size=testsize)
   413                                         ub.log('Done shuffling...')
   414                                         print x_train.shape
   415                                         print x_val.shape
   416                                         del df_train
   417                                         gc.collect()
   418                                         ub.log('Deleted df_train')
   419                             
   420                                         xgtrain = xgb.DMatrix(x_train, y_train, feature_names=feature_names)
   421                                         ub.log('Assembled xgtrain')
   422                                         xgval = xgb.DMatrix(x_val, y_val, feature_names=feature_names)
   423                                         ub.log('Assembled xgval')
   424                                         del x_train
   425                                         del x_val
   426                                         gc.collect()
   427                             
   428  36758.7 MiB      0.0 MiB           fname_xgtrain = os.path.join(ub.processed_data_dir, 'xgtrain_{}.buffer'.format(postfix_train))
   429  37498.8 MiB    740.1 MiB           xgtrain.save_binary(fname_xgtrain)
   430  37498.8 MiB      0.0 MiB           ub.log('Saved {}'.format(fname_xgtrain))
   431                             
   432  37498.8 MiB      0.0 MiB           fname_xgval = os.path.join(ub.processed_data_dir, 'xgval_{}.buffer'.format(postfix_train))
   433  37499.4 MiB      0.6 MiB           xgval.save_binary(fname_xgval)
   434  37499.4 MiB      0.0 MiB           ub.log('Saved {}'.format(fname_xgval))
   435                             
   436  39650.6 MiB   2151.2 MiB           xgtest = xgb.DMatrix(df_test.values, feature_names=feature_names)
   437  39650.6 MiB      0.0 MiB           ub.log('Assembled xgtest')
   438  39650.6 MiB      0.0 MiB           fname_xgtest = os.path.join(ub.processed_data_dir, 'xgtest_{}.buffer'.format(postfix_test))
   439  39666.5 MiB     15.9 MiB           xgtest.save_binary(fname_xgtest)
   440  39666.5 MiB      0.0 MiB           ub.log('Saved {}'.format(fname_xgtest))
   441                             
   442  39666.5 MiB      0.0 MiB           del df_test
   443  39670.1 MiB      3.5 MiB           gc.collect()
   444  39670.1 MiB      0.0 MiB           ub.log('Deleted df_test')
   445                             
   446  39670.1 MiB      0.0 MiB           print 'train and val set sizes'
   447  39670.6 MiB      0.6 MiB           print xgtrain.num_row(), xgtrain.num_col()
   448  39670.6 MiB      0.0 MiB           print xgval.num_row(), xgval.num_col()
   449                             
   450  39670.6 MiB      0.0 MiB           run_info['fname_xgtrain'] = fname_xgtrain
   451  39670.6 MiB      0.0 MiB           run_info['fname_xgval'] = fname_xgval
   452  39670.6 MiB      0.0 MiB           run_info['fname_xgtest'] = fname_xgtest
   453                             
   454  39670.6 MiB      0.0 MiB           xgb_params = get_params(basescore=prior)
   455  39670.6 MiB      0.0 MiB           run_info['xgb_params'] = xgb_params
   456  39670.6 MiB      0.0 MiB           ub.log('Get xgb_params')
   457  39670.6 MiB      0.0 MiB           print xgb_params
   458                             
   459  39670.6 MiB      0.0 MiB           xgb_num_rounds = 2000
   460  39670.6 MiB      0.0 MiB           run_info['xgb_num_rounds'] = xgb_num_rounds
   461  39670.6 MiB      0.0 MiB           print 'xgb_num_rounds', xgb_num_rounds
   462  39670.6 MiB      0.0 MiB           if cv:
   463                                         ub.log('Running cross validation...')
   464                                         eval_hist = xgb.cv(xgb_params, xgtrain, num_boost_round=xgb_num_rounds,
   465                                                            early_stopping_rounds=early_stop_rounds,
   466                                                            feval=ub.mcc_eval, maximize=True,
   467                                                            verbose_eval=1, show_stdv=True, nfold=4, seed=0, stratified=True)
   468                                         print eval_hist
   469                                         run_info['eval_hist'] = eval_hist
   470                             
   471                                     else:
   472  39670.6 MiB      0.0 MiB               ub.log('Running training...')
   473  39670.6 MiB      0.0 MiB               feature_imp_fname = feature_imp_fname_tmplate.format(postfix_train)
   474  39670.6 MiB      0.0 MiB               watchlist = [(xgtrain, 'train'), (xgval, 'eval')]
   475  39670.6 MiB      0.0 MiB               model = xgb.train(xgb_params, xgtrain, num_boost_round=xgb_num_rounds,
   476  39670.6 MiB      0.0 MiB                                 early_stopping_rounds=early_stop_rounds,
   477  39670.6 MiB      0.0 MiB                                 feval=ub.mcc_eval, maximize=True,
   478  44481.5 MiB   4810.9 MiB                                 evals=watchlist, verbose_eval=True)
   479                             
   480  44481.5 MiB      0.0 MiB               model_fname = os.path.join(ub.output_dir, 'xbg_{}.model'.format(postfix_train))
   481  44481.5 MiB      0.0 MiB               ub.log('Saving model: {}...'.format(model_fname))
   482  44481.5 MiB      0.0 MiB               model.save_model(model_fname)
   483  44481.9 MiB      0.4 MiB               model.dump_model(model_fname + '.raw.txt')
   484  44481.9 MiB      0.0 MiB               run_info['model_fname'] = model_fname
   485                             
   486  44481.9 MiB      0.0 MiB               ntree_limit = model.best_iteration + 1
   487                             
   488  44481.9 MiB      0.0 MiB               ub.log('Predictions on xgtrain...', 'highlight')
   489  44481.9 MiB      0.0 MiB               predictions = model.predict(xgtrain, ntree_limit=ntree_limit)
   490                             
   491  44481.9 MiB      0.0 MiB               best_proba, best_mcc, y_pred = ub.eval_mcc(y_train, predictions, True)
   492  44485.9 MiB      4.0 MiB               mcc_official = matthews_corrcoef(y_train, y_pred)
   493  44485.9 MiB      0.0 MiB               print 'ntree limit:', ntree_limit
   494  44485.9 MiB      0.0 MiB               print 'best_mcc:', best_mcc
   495  44485.9 MiB      0.0 MiB               print 'best_proba:', best_proba
   496  44485.9 MiB      0.0 MiB               print 'matthews_corroef', mcc_official
   497                             
   498  44485.9 MiB      0.0 MiB               ub.log('Predictions on xgval...', 'highlight')
   499  44485.9 MiB      0.0 MiB               predictions = model.predict(xgval, ntree_limit=ntree_limit)
   500                             
   501  44485.4 MiB     -0.6 MiB               best_proba, best_mcc, y_pred = ub.eval_mcc(y_val, predictions, True)
   502  44489.8 MiB      4.4 MiB               mcc_official = matthews_corrcoef(y_val, y_pred)
   503  44489.8 MiB      0.0 MiB               print 'ntree limit:', ntree_limit
   504  44489.8 MiB      0.0 MiB               print 'best_mcc:', best_mcc
   505  44489.8 MiB      0.0 MiB               print 'best_proba:', best_proba
   506  44489.8 MiB      0.0 MiB               print 'matthews_corroef', mcc_official
   507                             
   508  44489.8 MiB      0.0 MiB               run_info['ntree_limit'] = ntree_limit
   509  44489.8 MiB      0.0 MiB               run_info['best_mcc'] = best_mcc
   510  44489.8 MiB      0.0 MiB               run_info['best_proba'] = best_proba
   511  44489.8 MiB      0.0 MiB               run_info['mcc_official'] = mcc_official
   512                             
   513  44489.8 MiB      0.0 MiB               if analyze_feature_importance:
   514  44489.8 MiB      0.0 MiB                   ub.log('Analyzing feature importance...')
   515  44490.0 MiB      0.1 MiB                   imp = model.get_fscore()
   516  44490.0 MiB      0.0 MiB                   imp = sorted(imp.items(), key=operator.itemgetter(1))
   517  44490.4 MiB      0.5 MiB                   imp_df = pd.DataFrame(imp, columns=['feature', 'fscore'])
   518  44491.3 MiB      0.9 MiB                   imp_df['fscore'] = imp_df['fscore'] / imp_df['fscore'].sum()
   519                             
   520  44491.3 MiB      0.0 MiB                   ub.log('Output result csv to {}...'.format(feature_imp_fname + '.csv'))
   521  44491.8 MiB      0.6 MiB                   imp_df.to_csv(feature_imp_fname + '.csv')
   522                             
   523  44514.7 MiB     22.8 MiB                   plt.figure()
   524  44535.5 MiB     20.8 MiB                   imp_df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(6, 10))
   525  44535.7 MiB      0.2 MiB                   plt.title('XGBoost Feature Importance @ {}'.format(postfix_train))
   526  44535.7 MiB      0.0 MiB                   plt.xlabel('relative importance')
   527  44546.4 MiB     10.8 MiB                   plt.gcf().savefig(feature_imp_fname + '.png', bbox_inches='tight')
   528                             
   529  44546.4 MiB      0.0 MiB                   feature_lists = glob.glob(feature_imp_fname_tmplate.replace('{}', '*.csv'))
   530  44546.4 MiB      0.0 MiB                   ub.log('Aggregating previous analysis results...')
   531  44546.4 MiB      0.0 MiB                   print feature_lists
   532  44546.4 MiB      0.0 MiB                   features_df = None
   533  44546.4 MiB      0.0 MiB                   if feature_lists:
   534  44547.0 MiB      0.5 MiB                       for f_l in feature_lists:
   535  44547.0 MiB      0.0 MiB                           tmp_df = pd.read_csv(f_l, index_col=0)
   536  44547.0 MiB      0.0 MiB                           if features_df is None:
   537  44547.0 MiB      0.0 MiB                               features_df = tmp_df
   538                                                     else:
   539  44547.0 MiB      0.0 MiB                               features_df = pd.concat([features_df, tmp_df], ignore_index=True)
   540                             
   541  44547.3 MiB      0.4 MiB                   f_df = features_df.groupby(['feature']).mean().reset_index()
   542  44547.3 MiB      0.0 MiB                   f_df['overall'] = True
   543  44547.3 MiB      0.0 MiB                   imp_df['overall'] = False
   544  44547.3 MiB      0.0 MiB                   merged_df = pd.concat([imp_df, f_df]).sort_values(by=['overall', 'fscore'], ascending=False)
   545  44547.3 MiB      0.0 MiB                   sns_plot = sns.factorplot(y='feature', x='fscore', data=merged_df, hue='overall', kind='bar',
   546  44625.3 MiB     78.0 MiB                                             hue_order=[True, False], size=20, aspect=0.5)
   547  44643.6 MiB     18.3 MiB                   sns_plot.savefig(feature_imp_fname + '_overall.png', bbox_inches='tight')
   548                             
   549  44643.6 MiB      0.0 MiB                   ub.log('Output overall result csv to {}...'.format(top_features_fname))
   550  44643.6 MiB      0.0 MiB                   with open(top_features_fname, 'w') as tf:
   551  44643.6 MiB      0.0 MiB                       tf.write('\n'.join(list(set(merged_df.feature.values))))
   552                             
   553  44643.6 MiB      0.0 MiB                   merged_df.to_csv(top_features_fname.replace('.txt', '_df.csv'), index=False)
   554                             
   555  44643.6 MiB      0.0 MiB           run_info_fname = os.path.join(ub.output_dir, 'run_info_{}.txt'.format(postfix_train))
   556  44643.6 MiB      0.0 MiB           ub.log('Saving run_info into {}'.format(run_info_fname))
   557  44643.6 MiB      0.0 MiB           print run_info
   558  44643.6 MiB      0.0 MiB           with open(run_info_fname, 'w') as fp:
   559  44643.6 MiB      0.0 MiB               fp.write(str(run_info))
   560                             
   561                                         # json has trouble serializing np.float32
   562                                         # with open(run_info_fname, 'w') as fp:
   563                                         #    json.dump(run_info, fp)
   564                                 else:
   565                                     ub.log('Loading run info from {} ...'.format(run_info_fname))
   566                                     with open(run_info_fname, 'r') as fp:
   567                                         run_info = eval(fp.read())
   568                                     print json.dumps(run_info, indent=2)
   569                             
   570                                     model = xgb.Booster()
   571                                     ub.log('Loading model {} ...'.format(run_info['model_fname']))
   572                                     model.load_model(run_info['model_fname'])
   573                                     ub.log('Loading xgtest data {} ...'.format(run_info['fname_xgtest']))
   574                                     xgtest = xgb.DMatrix(run_info['fname_xgtest'])
   575                                     ub.log('XGB making predictions...')
   576                                     ypred = model.predict(xgtest, ntree_limit=run_info['ntree_limit'])
   577                             
   578                                     nrows = len(ypred)
   579                                     postfix_train = run_info['postfix_train']
   580                             
   581                                     sample = pd.read_csv(os.path.join(ub.data_dir, 'sample_submission.csv'), nrows=nrows)
   582                                     sample['Response'] = ypred
   583                                     fname_output = os.path.join(ub.output_dir, "sub_xgboost_{}_prob.csv".format(postfix_train))
   584                                     ub.log('Writing output file (raw proba) {} ...'.format(fname_output))
   585                                     sample.to_csv(fname_output, index=False)
   586                             
   587                                     best_proba = run_info['best_proba']
   588                                     ub.log('Using threshold: best_proba == {}'.format(best_proba))
   589                                     sample['Response'] = (ypred > best_proba).astype(int)
   590                                     fname_output = os.path.join(ub.output_dir, "sub_xgboost_{}.csv".format(postfix_train))
   591                                     ub.log('Writing output file {} ...'.format(fname_output))
   592                                     sample.to_csv(fname_output, index=False)
   593  44643.6 MiB      0.0 MiB       return run_info_fname


Filename: explore2.py

Line #    Mem usage    Increment   Line Contents
================================================
   230  14592.6 MiB      0.0 MiB   @profile(stream=f_mem)
   231                             def main(run_info_fname=None,
   232                                      N_start=None,
   233                                      N_files_train=10,
   234                                      N_files_test=10,
   235                                      cv=False,
   236                                      # if True running cross validation if False, run single model training session and importance analysis
   237                                      feature_down_select=False,
   238                                      analyze_feature_importance=False,
   239                                      early_stop_rounds=10
   240                                      ):
   241  14592.6 MiB      0.0 MiB       datetime_str = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
   242                             
   243  14592.6 MiB      0.0 MiB       if run_info_fname is None:
   244                                     run_info = dict()
   245                                     N_splits = ub.N_split
   246                                     if N_files_train > N_splits:
   247                                         N_files_train = N_splits
   248                                     if N_files_test > N_splits:
   249                                         N_files_test = N_splits
   250                             
   251                                     do_filtering = False
   252                             
   253                                     if analyze_feature_importance:
   254                                         do_filtering = False
   255                             
   256                                     if feature_down_select:
   257                                         do_filtering = False
   258                                         analyze_feature_importance = False
   259                             
   260                                     run_info['N_splits'] = N_splits
   261                                     run_info['N_files_train'] = N_files_train
   262                                     run_info['N_files_test'] = N_files_test
   263                                     run_info['do_filtering'] = do_filtering
   264                                     run_info['feature_down_select'] = feature_down_select
   265                                     run_info['cv'] = cv
   266                                     run_info['analyze_feature_importance'] = analyze_feature_importance
   267                                     run_info['early_stop_rounds'] = early_stop_rounds
   268                             
   269                                     df_train, n_start = load_data(load_test=False, N_start=N_start, N_read=N_files_train, N_split=N_splits,
   270                                                                   shuffle=False,
   271                                                                   filter=do_filtering)
   272                                     df_test, _ = load_data(load_test=True, N_start=n_start, N_read=N_files_test, N_split=N_splits, shuffle=False,
   273                                                            filter=do_filtering)
   274                             
   275                                     ub.log('generating id diff columns based on various dates columns')
   276                                     dates_cols = [x for x in list(df_train.columns) if 'start_date' in x or 'end_date' in x]
   277                             
   278                                     # print dates_cols
   279                             
   280                                     df_datesort = pd.concat([df_train[['Id'] + dates_cols], df_test[['Id'] + dates_cols]],
   281                                                             ignore_index=True)
   282                                     gc.collect()
   283                             
   284                                     for c in dates_cols:
   285                                         df_datesort.sort_values(by=[c, 'Id'], inplace=True)
   286                                         df_datesort[c + '_id_diff'] = df_datesort['Id'].diff().fillna(999999).astype(int)
   287                                         df_datesort[c + '_id_diff_reverse'] = df_datesort['Id'].iloc[::-1].diff().fillna(999999).astype(int)
   288                             
   289                                         df_datesort.drop([c], axis=1, inplace=True)
   290                             
   291                                     df_datesort.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_datesort_debug.csv'))
   292                             
   293                                     gc.collect()
   294                                     df_train = df_train.merge(df_datesort, on='Id')
   295                                     df_train.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_train_debug.csv'))
   296                             
   297                                     gc.collect()
   298                                     df_test = df_test.merge(df_datesort, on='Id')
   299                                     df_test.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_test_debug.csv'))
   300                             
   301                                     df_test['Response'] = 0
   302                             
   303                                     print df_train.shape
   304                                     print df_test.shape
   305                                     gc.collect()
   306                             
   307                                     if N_files_train == N_splits:
   308                                         split_data(df_train,
   309                                                    output_fname_template=os.path.join(ub.processed_data_dir, 'df_train_preprocessed_part{}.csv'))
   310                                     if N_files_test == N_splits:
   311                                         split_data(df_test,
   312                                                    output_fname_template=os.path.join(ub.processed_data_dir, 'df_test_preprocessed_part{}.csv'))
   313                             
   314                                     fillna = True
   315                                     run_info['fillna'] = fillna
   316                                     if fillna:
   317                                         ub.log('Filling na...')
   318                                         for df in [df_train, df_test]:
   319                                             cols_full_flag = df.isnull().any()
   320                                             non_full_cols = list(cols_full_flag[cols_full_flag].index)
   321                                             print 'Non-full columns: {}'.format(len(non_full_cols))
   322                                             # print non_full_cols
   323                             
   324                                             if 1:
   325                                                 df.fillna(-999999, inplace=True)
   326                                             else:
   327                                                 # print df.PersonalField7.unique()
   328                                                 for c in non_full_cols:
   329                                                     if len(df[c].unique()) > 2:
   330                                                         most_frequent_items = df[c].value_counts().idxmax()
   331                                                         print c, most_frequent_items
   332                                                         df[c].fillna(value=most_frequent_items, inplace=True)
   333                                                     else:  # if it is only a pair of value [somthing, nan] then fill in "missing"
   334                                                         df[c].fillna(value='missing', inplace=True)
   335                                                         print c, df[c].unique()
   336                             
   337                                             cols_full_flag = df.isnull().any()
   338                                             non_full_cols = list(cols_full_flag[cols_full_flag].index)
   339                                             print 'Non-full columns: {}'.format(len(non_full_cols))
   340                             
   341                                             le = LabelEncoder()
   342                                             obj_cols = df.select_dtypes(include=['object']).columns
   343                                             # print 'Obj columns: ', list(obj_cols)
   344                                             for col in obj_cols:
   345                                                 df[col] = le.fit_transform(df[col])
   346                             
   347                                         df_train.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_train_cleanup_debug.csv'))
   348                                         df_test.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_train_cleanup_debug.csv'))
   349                             
   350                                     ub.log('Dropping Id and Response columns...')
   351                                     columns_to_drop = ['Id', 'Response']
   352                                     shuffle_col = df_train[['Id']].copy()
   353                                     shuffle_col['Id'] = np.random.randn(len(shuffle_col))
   354                             
   355                                     y_total_df = df_train['Response']
   356                                     y_total = df_train['Response'].values
   357                                     df_train.drop(columns_to_drop, axis=1, inplace=True)
   358                                     df_test.drop(columns_to_drop, axis=1, inplace=True)
   359                             
   360                                     print df_train.shape
   361                                     print df_test.shape
   362                                     prior = np.sum(y_total) / (1. * len(y_total))
   363                                     print 'prior: {}'.format(prior)
   364                                     run_info['prior'] = prior
   365                                     gc.collect()
   366                             
   367                                     feature_imp_fname_tmplate = os.path.join(ub.output_dir, 'feature_importance_xgb_{}')
   368                                     top_features_fname = feature_imp_fname_tmplate.format('accumu_list.txt')
   369                                     if feature_down_select:
   370                                         ub.log('Feature down selected based on {}...'.format(top_features_fname))
   371                                         #todo may need to set a maxN for the number of features to use
   372                                         
   373                                         with open(top_features_fname, 'r') as tf:
   374                                             selected_cols = [x.strip() for x in tf.readlines()]
   375                                         df_train = df_train[selected_cols]
   376                                         df_test = df_test[selected_cols]
   377                                         print df_train.shape
   378                                         print df_test.shape
   379                                         print df_train.columns
   380                             
   381                                     feature_names = list(df_train.columns)
   382                             
   383                                     postfix_train = '{}_{}of{}'.format(datetime_str, N_files_train, N_splits)
   384                                     postfix_test = '{}_{}of{}'.format(datetime_str, N_files_test, N_splits)
   385                             
   386                                     run_info['postfix_train'] = postfix_train
   387                                     run_info['postfix_test'] = postfix_test
   388                             
   389                                     testsize = 0.3
   390                                     run_info['testsize'] = testsize
   391                             
   392                                     train_test_split_method = 1
   393                             
   394                                     ub.log('Train/val split using testsize={}, split_method={}'.format(testsize, train_test_split_method))
   395                                     if train_test_split_method == 1:
   396                                         train_idx = shuffle_col[shuffle_col['Id'] > testsize].index
   397                                         val_idx = shuffle_col[shuffle_col['Id'] <= testsize].index
   398                                         ub.log('Done shuffling...')
   399                                         print 'len of train_idx', len(train_idx)
   400                                         print 'len of val_idx', len(val_idx)
   401                                         y_train = y_total_df.loc[train_idx].values
   402                                         y_val = y_total_df.loc[val_idx].values
   403                             
   404                                         xgtrain = xgb.DMatrix(df_train.loc[train_idx].values, y_train, feature_names=feature_names)
   405                                         ub.log('Assembled xgtrain')
   406                                         xgval = xgb.DMatrix(df_train.loc[val_idx].values, y_val, feature_names=feature_names)
   407                                         ub.log('Assembled xgval')
   408                                         del df_train
   409                                         ub.log('Deleted df_train')
   410                                         gc.collect()
   411                                     else:
   412                                         x_train, x_val, y_train, y_val = train_test_split(df_train.values, y_total, test_size=testsize)
   413                                         ub.log('Done shuffling...')
   414                                         print x_train.shape
   415                                         print x_val.shape
   416                                         del df_train
   417                                         gc.collect()
   418                                         ub.log('Deleted df_train')
   419                             
   420                                         xgtrain = xgb.DMatrix(x_train, y_train, feature_names=feature_names)
   421                                         ub.log('Assembled xgtrain')
   422                                         xgval = xgb.DMatrix(x_val, y_val, feature_names=feature_names)
   423                                         ub.log('Assembled xgval')
   424                                         del x_train
   425                                         del x_val
   426                                         gc.collect()
   427                             
   428                                     fname_xgtrain = os.path.join(ub.processed_data_dir, 'xgtrain_{}.buffer'.format(postfix_train))
   429                                     xgtrain.save_binary(fname_xgtrain)
   430                                     ub.log('Saved {}'.format(fname_xgtrain))
   431                             
   432                                     fname_xgval = os.path.join(ub.processed_data_dir, 'xgval_{}.buffer'.format(postfix_train))
   433                                     xgval.save_binary(fname_xgval)
   434                                     ub.log('Saved {}'.format(fname_xgval))
   435                             
   436                                     xgtest = xgb.DMatrix(df_test.values, feature_names=feature_names)
   437                                     ub.log('Assembled xgtest')
   438                                     fname_xgtest = os.path.join(ub.processed_data_dir, 'xgtest_{}.buffer'.format(postfix_test))
   439                                     xgtest.save_binary(fname_xgtest)
   440                                     ub.log('Saved {}'.format(fname_xgtest))
   441                             
   442                                     del df_test
   443                                     gc.collect()
   444                                     ub.log('Deleted df_test')
   445                             
   446                                     print 'train and val set sizes'
   447                                     print xgtrain.num_row(), xgtrain.num_col()
   448                                     print xgval.num_row(), xgval.num_col()
   449                             
   450                                     run_info['fname_xgtrain'] = fname_xgtrain
   451                                     run_info['fname_xgval'] = fname_xgval
   452                                     run_info['fname_xgtest'] = fname_xgtest
   453                             
   454                                     xgb_params = get_params(basescore=prior)
   455                                     run_info['xgb_params'] = xgb_params
   456                                     ub.log('Get xgb_params')
   457                                     print xgb_params
   458                             
   459                                     xgb_num_rounds = 2000
   460                                     run_info['xgb_num_rounds'] = xgb_num_rounds
   461                                     print 'xgb_num_rounds', xgb_num_rounds
   462                                     if cv:
   463                                         ub.log('Running cross validation...')
   464                                         eval_hist = xgb.cv(xgb_params, xgtrain, num_boost_round=xgb_num_rounds,
   465                                                            early_stopping_rounds=early_stop_rounds,
   466                                                            feval=ub.mcc_eval, maximize=True,
   467                                                            verbose_eval=1, show_stdv=True, nfold=4, seed=0, stratified=True)
   468                                         print eval_hist
   469                                         run_info['eval_hist'] = eval_hist
   470                             
   471                                     else:
   472                                         ub.log('Running training...')
   473                                         feature_imp_fname = feature_imp_fname_tmplate.format(postfix_train)
   474                                         watchlist = [(xgtrain, 'train'), (xgval, 'eval')]
   475                                         model = xgb.train(xgb_params, xgtrain, num_boost_round=xgb_num_rounds,
   476                                                           early_stopping_rounds=early_stop_rounds,
   477                                                           feval=ub.mcc_eval, maximize=True,
   478                                                           evals=watchlist, verbose_eval=True)
   479                             
   480                                         model_fname = os.path.join(ub.output_dir, 'xbg_{}.model'.format(postfix_train))
   481                                         ub.log('Saving model: {}...'.format(model_fname))
   482                                         model.save_model(model_fname)
   483                                         model.dump_model(model_fname + '.raw.txt')
   484                                         run_info['model_fname'] = model_fname
   485                             
   486                                         ntree_limit = model.best_iteration + 1
   487                             
   488                                         ub.log('Predictions on xgtrain...', 'highlight')
   489                                         predictions = model.predict(xgtrain, ntree_limit=ntree_limit)
   490                             
   491                                         best_proba, best_mcc, y_pred = ub.eval_mcc(y_train, predictions, True)
   492                                         mcc_official = matthews_corrcoef(y_train, y_pred)
   493                                         print 'ntree limit:', ntree_limit
   494                                         print 'best_mcc:', best_mcc
   495                                         print 'best_proba:', best_proba
   496                                         print 'matthews_corroef', mcc_official
   497                             
   498                                         ub.log('Predictions on xgval...', 'highlight')
   499                                         predictions = model.predict(xgval, ntree_limit=ntree_limit)
   500                             
   501                                         best_proba, best_mcc, y_pred = ub.eval_mcc(y_val, predictions, True)
   502                                         mcc_official = matthews_corrcoef(y_val, y_pred)
   503                                         print 'ntree limit:', ntree_limit
   504                                         print 'best_mcc:', best_mcc
   505                                         print 'best_proba:', best_proba
   506                                         print 'matthews_corroef', mcc_official
   507                             
   508                                         run_info['ntree_limit'] = ntree_limit
   509                                         run_info['best_mcc'] = best_mcc
   510                                         run_info['best_proba'] = best_proba
   511                                         run_info['mcc_official'] = mcc_official
   512                             
   513                                         if analyze_feature_importance:
   514                                             ub.log('Analyzing feature importance...')
   515                                             imp = model.get_fscore()
   516                                             imp = sorted(imp.items(), key=operator.itemgetter(1))
   517                                             imp_df = pd.DataFrame(imp, columns=['feature', 'fscore'])
   518                                             imp_df['fscore'] = imp_df['fscore'] / imp_df['fscore'].sum()
   519                             
   520                                             ub.log('Output result csv to {}...'.format(feature_imp_fname + '.csv'))
   521                                             imp_df.to_csv(feature_imp_fname + '.csv')
   522                             
   523                                             plt.figure()
   524                                             imp_df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(6, 10))
   525                                             plt.title('XGBoost Feature Importance @ {}'.format(postfix_train))
   526                                             plt.xlabel('relative importance')
   527                                             plt.gcf().savefig(feature_imp_fname + '.png', bbox_inches='tight')
   528                             
   529                                             feature_lists = glob.glob(feature_imp_fname_tmplate.replace('{}', '*.csv'))
   530                                             ub.log('Aggregating previous analysis results...')
   531                                             print feature_lists
   532                                             features_df = None
   533                                             if feature_lists:
   534                                                 for f_l in feature_lists:
   535                                                     tmp_df = pd.read_csv(f_l, index_col=0)
   536                                                     if features_df is None:
   537                                                         features_df = tmp_df
   538                                                     else:
   539                                                         features_df = pd.concat([features_df, tmp_df], ignore_index=True)
   540                             
   541                                             f_df = features_df.groupby(['feature']).mean().reset_index()
   542                                             f_df['overall'] = True
   543                                             imp_df['overall'] = False
   544                                             merged_df = pd.concat([imp_df, f_df]).sort_values(by=['overall', 'fscore'], ascending=False)
   545                                             sns_plot = sns.factorplot(y='feature', x='fscore', data=merged_df, hue='overall', kind='bar',
   546                                                                       hue_order=[True, False], size=20, aspect=0.5)
   547                                             sns_plot.savefig(feature_imp_fname + '_overall.png', bbox_inches='tight')
   548                             
   549                                             ub.log('Output overall result csv to {}...'.format(top_features_fname))
   550                                             with open(top_features_fname, 'w') as tf:
   551                                                 tf.write('\n'.join(list(set(merged_df.feature.values))))
   552                             
   553                                             merged_df.to_csv(top_features_fname.replace('.txt', '_df.csv'), index=False)
   554                             
   555                                     run_info_fname = os.path.join(ub.output_dir, 'run_info_{}.txt'.format(postfix_train))
   556                                     ub.log('Saving run_info into {}'.format(run_info_fname))
   557                                     print run_info
   558                                     with open(run_info_fname, 'w') as fp:
   559                                         fp.write(str(run_info))
   560                             
   561                                         # json has trouble serializing np.float32
   562                                         # with open(run_info_fname, 'w') as fp:
   563                                         #    json.dump(run_info, fp)
   564                                 else:
   565  14592.6 MiB      0.0 MiB           ub.log('Loading run info from {} ...'.format(run_info_fname))
   566  14592.6 MiB      0.0 MiB           with open(run_info_fname, 'r') as fp:
   567  14592.6 MiB      0.0 MiB               run_info = eval(fp.read())
   568  14592.8 MiB      0.2 MiB           print json.dumps(run_info, indent=2)
   569                             
   570  14592.8 MiB      0.0 MiB           model = xgb.Booster()
   571  14592.8 MiB      0.0 MiB           ub.log('Loading model {} ...'.format(run_info['model_fname']))
   572  14592.8 MiB      0.0 MiB           model.load_model(run_info['model_fname'])
   573  14592.8 MiB      0.0 MiB           ub.log('Loading xgtest data {} ...'.format(run_info['fname_xgtest']))
   574  27212.5 MiB  12619.7 MiB           xgtest = xgb.DMatrix(run_info['fname_xgtest'])
   575  27212.5 MiB      0.0 MiB           ub.log('XGB making predictions...')
   576  27213.9 MiB      1.4 MiB           ypred = model.predict(xgtest, ntree_limit=run_info['ntree_limit'])
   577                             
   578  27213.9 MiB      0.0 MiB           nrows = len(ypred)
   579  27213.9 MiB      0.0 MiB           postfix_train = run_info['postfix_train']
   580                             
   581  27232.3 MiB     18.4 MiB           sample = pd.read_csv(os.path.join(ub.data_dir, 'sample_submission.csv'), nrows=nrows)
   582  27232.8 MiB      0.5 MiB           sample['Response'] = ypred
   583  27232.8 MiB      0.0 MiB           fname_output = os.path.join(ub.output_dir, "sub_xgboost_{}_prob.csv".format(postfix_train))
   584  27232.8 MiB      0.0 MiB           ub.log('Writing output file (raw proba) {} ...'.format(fname_output))
   585  27235.1 MiB      2.3 MiB           sample.to_csv(fname_output, index=False)
   586                             
   587  27235.1 MiB      0.0 MiB           best_proba = run_info['best_proba']
   588  27235.1 MiB      0.0 MiB           ub.log('Using threshold: best_proba == {}'.format(best_proba))
   589  27237.5 MiB      2.3 MiB           sample['Response'] = (ypred > best_proba).astype(int)
   590  27237.5 MiB      0.0 MiB           fname_output = os.path.join(ub.output_dir, "sub_xgboost_{}.csv".format(postfix_train))
   591  27237.5 MiB      0.0 MiB           ub.log('Writing output file {} ...'.format(fname_output))
   592  27238.5 MiB      1.0 MiB           sample.to_csv(fname_output, index=False)
   593  27238.5 MiB      0.0 MiB       return run_info_fname


