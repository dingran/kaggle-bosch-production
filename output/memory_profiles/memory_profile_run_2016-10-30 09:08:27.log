Filename: main_bosch.py

Line #    Mem usage    Increment   Line Contents
================================================
   364    171.3 MiB      0.0 MiB   @profile(stream=f_mem)
   365                             def main(run_info_fname=None,
   366                                      compile_data=False,
   367                                      train_model=False,
   368                                      make_submission=False,
   369                                      N_start=None,
   370                                      N_files_train=1,
   371                                      N_files_test=1,
   372                                      original_cols_only=False,
   373                                      disable_id_diff_cols=False,
   374                             
   375                                      feature_list_file=None,
   376                                      analyze_feature_importance=False,
   377                                      cv=False,
   378                                      # if True running cross validation if False, run single model training session and importance analysis
   379                                      early_stop_rounds=10,
   380                                      N_rounds=1000,
   381                                      testsize=0.1,
   382                                      xgb_params=None,
   383                             
   384                                      skip_date_csv=False,
   385                                      skip_num_csv=False,
   386                                      skip_cat_csv=False
   387                                      ):
   388    171.3 MiB      0.0 MiB       datetime_str = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
   389                             
   390    171.3 MiB      0.0 MiB       if compile_data:
   391    171.3 MiB      0.0 MiB           run_info = dict()
   392    171.3 MiB      0.0 MiB           N_splits = ub.N_split
   393    171.3 MiB      0.0 MiB           if N_files_train > N_splits:
   394                                         N_files_train = N_splits
   395    171.3 MiB      0.0 MiB           if N_files_test > N_splits:
   396                                         N_files_test = N_splits
   397                             
   398    171.3 MiB      0.0 MiB           if analyze_feature_importance and (feature_list_file is not None):
   399                                         assert 0
   400                             
   401    171.3 MiB      0.0 MiB           run_info['compile_data'] = compile_data
   402    171.3 MiB      0.0 MiB           run_info['N_splits'] = N_splits
   403    171.3 MiB      0.0 MiB           run_info['N_start'] = N_start
   404    171.3 MiB      0.0 MiB           run_info['N_files_train'] = N_files_train
   405    171.3 MiB      0.0 MiB           run_info['N_files_test'] = N_files_test
   406    171.3 MiB      0.0 MiB           run_info['original_cols_only'] = original_cols_only
   407    171.3 MiB      0.0 MiB           run_info['disable_id_diff_cols'] = disable_id_diff_cols
   408    171.3 MiB      0.0 MiB           run_info['features_list_file'] = feature_list_file
   409    171.3 MiB      0.0 MiB           run_info['skip_date_csv'] = skip_date_csv
   410    171.3 MiB      0.0 MiB           run_info['skip_num_csv'] = skip_num_csv
   411    171.3 MiB      0.0 MiB           run_info['skip_cat_csv'] = skip_cat_csv
   412                             
   413    171.3 MiB      0.0 MiB           df_train, n_start = load_data(load_test=False, N_start=N_start, N_read=N_files_train, N_split=N_splits,
   414    171.3 MiB      0.0 MiB                                         original_cols_only=original_cols_only,
   415    171.3 MiB      0.0 MiB                                         feature_list_file=feature_list_file,
   416    171.3 MiB      0.0 MiB                                         load_categorical_csv=(not skip_cat_csv),
   417    171.3 MiB      0.0 MiB                                         load_date_csv=(not skip_date_csv),
   418  14239.1 MiB  14067.8 MiB                                         load_numerical_csv=(not skip_num_csv))
   419  14239.1 MiB      0.0 MiB           df_test, _ = load_data(load_test=True, N_start=n_start, N_read=N_files_test, N_split=N_splits,
   420  14239.1 MiB      0.0 MiB                                  original_cols_only=original_cols_only,
   421  14239.1 MiB      0.0 MiB                                  feature_list_file=feature_list_file,
   422  14239.1 MiB      0.0 MiB                                  load_categorical_csv=(not skip_cat_csv),
   423  14239.1 MiB      0.0 MiB                                  load_date_csv=(not skip_date_csv),
   424  27833.9 MiB  13594.8 MiB                                  load_numerical_csv=(not skip_num_csv))
   425                             
   426  27833.9 MiB      0.0 MiB           if not disable_id_diff_cols:
   427  27833.9 MiB      0.0 MiB               diff_period = 1
   428  27833.9 MiB      0.0 MiB               ub.log('generating id diff columns based on various dates columns: diff_period = {}'.format(diff_period))
   429  27833.9 MiB      0.0 MiB               dates_cols = [x for x in list(df_train.columns) if
   430  27833.9 MiB      0.0 MiB                             ('start_date' in x or 'end_date' in x) and ('rank' not in x)]
   431                             
   432                                         # print dates_cols
   433                             
   434  35793.4 MiB   7959.5 MiB               df_datesort = pd.concat([df_train[['Id'] + dates_cols], df_test[['Id'] + dates_cols]],
   435  36252.3 MiB    458.9 MiB                                       ignore_index=True)
   436  36252.3 MiB      0.0 MiB               gc.collect()
   437                             
   438  46937.9 MiB  10685.6 MiB               for c in dates_cols:
   439                                             # print c
   440  45885.8 MiB  -1052.1 MiB                   df_datesort.sort_values(by=[c, 'Id'], inplace=True)
   441  45885.8 MiB      0.0 MiB                   df_datesort[c + '_id_diff'] = df_datesort['Id'].diff(diff_period).fillna(999999).astype(int)
   442  45885.8 MiB      0.0 MiB                   df_datesort[c + '_id_diff_reverse'] = df_datesort['Id'].iloc[::-1].diff().fillna(999999).astype(int)
   443                                             df_datesort[c + '_id_diff_magic'] = \
   444  45647.7 MiB   -238.1 MiB                       1 + 2 * (df_datesort[c + '_id_diff'] > 1) + 1 * (df_datesort[c + '_id_diff_reverse'] < -1)
   445                             
   446  46937.9 MiB   1290.2 MiB                   df_datesort.drop([c], axis=1, inplace=True)
   447                             
   448  46479.0 MiB   -458.9 MiB               df_datesort.head(n=N_DEBUG_LINES).to_csv(os.path.join(ub.data_dir, 'df_datesort_debug.csv'))
   449                             
   450  37174.6 MiB  -9304.4 MiB               gc.collect()
   451  44615.1 MiB   7440.5 MiB               df_train = df_train.merge(df_datesort, on='Id')
   452                             
   453  34384.1 MiB -10230.9 MiB               gc.collect()
   454  43086.7 MiB   8702.6 MiB               df_test = df_test.merge(df_datesort, on='Id')
   455                             
   456  45290.0 MiB   2203.2 MiB           df_test['Response'] = 0
   457  45290.0 MiB      0.0 MiB           df_train.head(n=N_DEBUG_LINES).to_csv(os.path.join(ub.data_dir, 'df_train_debug.csv'))
   458  45290.0 MiB      0.0 MiB           df_test.head(n=N_DEBUG_LINES).to_csv(os.path.join(ub.data_dir, 'df_test_debug.csv'))
   459                             
   460  45290.0 MiB      0.0 MiB           print df_train.shape
   461  45290.0 MiB      0.0 MiB           print df_test.shape
   462  35061.2 MiB -10228.8 MiB           gc.collect()
   463                             
   464                                     # if N_files_train == N_splits:
   465                                     #     split_data(df_train,
   466                                     #                output_fname_template=os.path.join(ub.processed_data_dir, 'df_train_preprocessed_part{}.csv'))
   467                                     # if N_files_test == N_splits:
   468                                     #     split_data(df_test,
   469                                     #                output_fname_template=os.path.join(ub.processed_data_dir, 'df_test_preprocessed_part{}.csv'))
   470                             
   471  35061.2 MiB      0.0 MiB           fillna = True
   472  35061.2 MiB      0.0 MiB           run_info['fillna'] = fillna
   473  35061.2 MiB      0.0 MiB           if fillna:
   474  35061.2 MiB      0.0 MiB               ub.log('Filling na...')
   475  35061.2 MiB      0.0 MiB               for df in [df_train, df_test]:
   476  38540.1 MiB   3478.9 MiB                   cols_full_flag = df.isnull().any()
   477  38540.1 MiB      0.0 MiB                   non_full_cols = list(cols_full_flag[cols_full_flag].index)
   478  38540.1 MiB      0.0 MiB                   print 'Non-full columns: {}'.format(len(non_full_cols))
   479                                             # print non_full_cols
   480                             
   481                                             if 1:
   482  38540.3 MiB      0.2 MiB                       df.fillna(-999999, inplace=True)
   483                                             else:
   484                                                 # print df.PersonalField7.unique()
   485                                                 for c in non_full_cols:
   486                                                     if len(df[c].unique()) > 2:
   487                                                         most_frequent_items = df[c].value_counts().idxmax()
   488                                                         print c, most_frequent_items
   489                                                         df[c].fillna(value=most_frequent_items, inplace=True)
   490                                                     else:  # if it is only a pair of value [somthing, nan] then fill in "missing"
   491                                                         df[c].fillna(value='missing', inplace=True)
   492                                                         print c, df[c].unique()
   493                             
   494  38540.3 MiB      0.0 MiB                   cols_full_flag = df.isnull().any()
   495  38540.3 MiB      0.0 MiB                   non_full_cols = list(cols_full_flag[cols_full_flag].index)
   496  38540.3 MiB      0.0 MiB                   print 'Non-full columns: {}'.format(len(non_full_cols))
   497                             
   498  38540.3 MiB      0.0 MiB                   le = LabelEncoder()
   499  38540.3 MiB      0.0 MiB                   obj_cols = df.select_dtypes(include=['object']).columns
   500                                             # print 'Obj columns: ', list(obj_cols)
   501  38540.3 MiB      0.0 MiB                   for col in obj_cols:
   502  38538.3 MiB     -2.1 MiB                       df[col] = le.fit_transform(df[col])
   503                             
   504  31080.4 MiB  -7457.8 MiB               df_train.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_train_cleanup_debug.csv'))
   505  31080.4 MiB      0.0 MiB               df_test.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_train_cleanup_debug.csv'))
   506                             
   507  31080.4 MiB      0.0 MiB           ub.log('Dropping Id and Response columns...')
   508  31080.4 MiB      0.0 MiB           columns_to_drop = ['Id', 'Response']
   509  34741.2 MiB   3660.7 MiB           shuffle_col = df_train[['Id']].copy()
   510  34741.2 MiB      0.0 MiB           shuffle_col['Id'] = np.random.rand(len(shuffle_col))
   511                             
   512  34741.2 MiB      0.0 MiB           y_total_df = df_train['Response']
   513  34741.2 MiB      0.0 MiB           y_total = df_train['Response'].values
   514  39735.4 MiB   4994.2 MiB           df_train.drop(columns_to_drop, axis=1, inplace=True)
   515  43529.9 MiB   3794.5 MiB           df_test.drop(columns_to_drop, axis=1, inplace=True)
   516                             
   517  43529.9 MiB      0.0 MiB           print df_train.shape
   518  43529.9 MiB      0.0 MiB           print df_test.shape
   519  43529.9 MiB      0.0 MiB           prior = np.sum(y_total) / (1. * len(y_total))
   520  43529.9 MiB      0.0 MiB           print 'prior: {}'.format(prior)
   521  43529.9 MiB      0.0 MiB           run_info['prior'] = prior
   522                             
   523  43448.7 MiB    -81.2 MiB           gc.collect()
   524                             
   525  43448.7 MiB      0.0 MiB           feature_imp_fname_template = os.path.join(ub.output_dir, 'feature_importance_xgb_{}')
   526  43448.7 MiB      0.0 MiB           run_info['feature_imp_fname_template'] = feature_imp_fname_template
   527  43448.7 MiB      0.0 MiB           top_features_fname = feature_imp_fname_template.format('accumu_list.txt')
   528  43448.7 MiB      0.0 MiB           run_info['top_features_fname'] = top_features_fname
   529                             
   530                                     # if feature_down_select:
   531                                     #     ub.log('Feature down selected based on {}...'.format(top_features_fname))
   532                                     #     #todo may need to set a maxN for the number of features to use
   533                                     #
   534                                     #     with open(top_features_fname, 'r') as tf:
   535                                     #         selected_cols = [x.strip() for x in tf.readlines()]
   536                                     #     df_train = df_train[selected_cols]
   537                                     #     df_test = df_test[selected_cols]
   538                                     #     print df_train.shape
   539                                     #     print df_test.shape
   540                                     #     print df_train.columns
   541                             
   542  43448.7 MiB      0.0 MiB           feature_names = list(df_train.columns)
   543                             
   544  43448.7 MiB      0.0 MiB           postfix_train = '{}_{}of{}'.format(datetime_str, N_files_train, N_splits)
   545  43448.7 MiB      0.0 MiB           postfix_test = '{}_{}of{}'.format(datetime_str, N_files_test, N_splits)
   546                             
   547  43448.7 MiB      0.0 MiB           run_info['postfix_train'] = postfix_train
   548  43448.7 MiB      0.0 MiB           run_info['postfix_test'] = postfix_test
   549                             
   550  43448.7 MiB      0.0 MiB           run_info['testsize'] = testsize
   551                             
   552  43448.7 MiB      0.0 MiB           train_test_split_method = 1
   553                             
   554  43448.7 MiB      0.0 MiB           ub.log('Train/val split using testsize={}, split_method={}'.format(testsize, train_test_split_method))
   555  43448.7 MiB      0.0 MiB           if train_test_split_method == 1:
   556  43448.7 MiB      0.0 MiB               train_idx = shuffle_col[shuffle_col['Id'] > testsize].index
   557  43448.7 MiB      0.0 MiB               val_idx = shuffle_col[shuffle_col['Id'] <= testsize].index
   558  43448.7 MiB      0.0 MiB               ub.log('Done shuffling...')
   559  43448.7 MiB      0.0 MiB               print 'len of train_idx', len(train_idx)
   560  43448.7 MiB      0.0 MiB               print 'len of val_idx', len(val_idx)
   561  43448.7 MiB      0.0 MiB               y_train = y_total_df.loc[train_idx].values
   562  43448.7 MiB      0.0 MiB               y_val = y_total_df.loc[val_idx].values
   563                             
   564  39609.5 MiB  -3839.2 MiB               xgtrain = xgb.DMatrix(df_train.loc[train_idx].values, y_train, feature_names=feature_names)
   565  39609.5 MiB      0.0 MiB               ub.log('Assembled xgtrain')
   566  41454.1 MiB   1844.6 MiB               xgval = xgb.DMatrix(df_train.loc[val_idx].values, y_val, feature_names=feature_names)
   567  41454.1 MiB      0.0 MiB               ub.log('Assembled xgval')
   568  41454.1 MiB      0.0 MiB               del df_train
   569  41454.1 MiB      0.0 MiB               ub.log('Deleted df_train')
   570  30541.3 MiB -10912.8 MiB               gc.collect()
   571                                     else:
   572                                         x_train, x_val, y_train, y_val = train_test_split(df_train.values, y_total, test_size=testsize)
   573                                         ub.log('Done shuffling...')
   574                                         print x_train.shape
   575                                         print x_val.shape
   576                                         del df_train
   577                                         gc.collect()
   578                                         ub.log('Deleted df_train')
   579                             
   580                                         xgtrain = xgb.DMatrix(x_train, y_train, feature_names=feature_names)
   581                                         ub.log('Assembled xgtrain')
   582                                         xgval = xgb.DMatrix(x_val, y_val, feature_names=feature_names)
   583                                         ub.log('Assembled xgval')
   584                                         del x_train
   585                                         del x_val
   586                                         gc.collect()
   587                             
   588  30541.3 MiB      0.0 MiB           fname_xgtrain = os.path.join(ub.processed_data_dir, 'xgtrain_{}.buffer'.format(postfix_train))
   589  31137.6 MiB    596.3 MiB           xgtrain.save_binary(fname_xgtrain)
   590  31137.6 MiB      0.0 MiB           ub.log('Saved {}'.format(fname_xgtrain))
   591                             
   592  31137.6 MiB      0.0 MiB           fname_xgval = os.path.join(ub.processed_data_dir, 'xgval_{}.buffer'.format(postfix_train))
   593  31137.6 MiB      0.0 MiB           xgval.save_binary(fname_xgval)
   594  31137.6 MiB      0.0 MiB           ub.log('Saved {}'.format(fname_xgval))
   595                             
   596  39485.8 MiB   8348.2 MiB           xgtest = xgb.DMatrix(df_test.values, feature_names=feature_names)
   597  39485.8 MiB      0.0 MiB           ub.log('Assembled xgtest')
   598  39485.8 MiB      0.0 MiB           fname_xgtest = os.path.join(ub.processed_data_dir, 'xgtest_{}.buffer'.format(postfix_test))
   599  39488.6 MiB      2.8 MiB           xgtest.save_binary(fname_xgtest)
   600  39488.6 MiB      0.0 MiB           ub.log('Saved {}'.format(fname_xgtest))
   601                             
   602  39488.6 MiB      0.0 MiB           del df_test
   603  39488.6 MiB      0.0 MiB           gc.collect()
   604  39488.6 MiB      0.0 MiB           ub.log('Deleted df_test')
   605                             
   606  39488.6 MiB      0.0 MiB           print 'train and val set sizes'
   607  39490.3 MiB      1.7 MiB           print xgtrain.num_row(), xgtrain.num_col()
   608  39490.3 MiB      0.0 MiB           print xgval.num_row(), xgval.num_col()
   609  39490.3 MiB      0.0 MiB           run_info['xgtrain_nrows'] = xgtrain.num_row()
   610  39490.3 MiB      0.0 MiB           run_info['xgval_nrows'] = xgval.num_row()
   611                             
   612  39490.3 MiB      0.0 MiB           run_info['fname_xgtrain'] = fname_xgtrain
   613  39490.3 MiB      0.0 MiB           run_info['fname_xgval'] = fname_xgval
   614  39490.3 MiB      0.0 MiB           run_info['fname_xgtest'] = fname_xgtest
   615                             
   616  39490.3 MiB      0.0 MiB           fname_ytrain = os.path.join(ub.processed_data_dir, 'ytrain_{}.npy'.format(postfix_train))
   617  39490.3 MiB      0.0 MiB           fname_yval = os.path.join(ub.processed_data_dir, 'yval_{}.npy'.format(postfix_train))
   618                             
   619  39490.3 MiB      0.0 MiB           np.save(fname_ytrain, y_train)
   620  39490.3 MiB      0.0 MiB           ub.log('Saved ' + fname_ytrain)
   621                             
   622  39490.3 MiB      0.0 MiB           np.save(fname_yval, y_val)
   623  39490.3 MiB      0.0 MiB           ub.log('Saved ' + fname_yval)
   624                             
   625  39490.3 MiB      0.0 MiB           run_info['fname_ytrain'] = fname_ytrain
   626  39490.3 MiB      0.0 MiB           run_info['fname_yval'] = fname_yval
   627                             
   628  39490.3 MiB      0.0 MiB       if train_model:
   629  39490.3 MiB      0.0 MiB           assert compile_data or (run_info_fname is not None)
   630                             
   631  39490.3 MiB      0.0 MiB           run_info['cv'] = cv
   632  39490.3 MiB      0.0 MiB           run_info['analyze_feature_importance'] = analyze_feature_importance
   633  39490.3 MiB      0.0 MiB           run_info['early_stop_rounds'] = early_stop_rounds
   634                             
   635  39490.3 MiB      0.0 MiB           if not compile_data:
   636                                         ub.log('(train_model) Loading run info from {} ...'.format(run_info_fname))
   637                                         with open(run_info_fname, 'r') as fp:
   638                                             run_info = eval(fp.read())
   639                                         print json.dumps(run_info, indent=2)
   640                             
   641                                         run_info_fname = run_info_fname.replace('.txt', '_{}.txt'.format(datetime_str))
   642                             
   643                                         logged_home_dir = None
   644                                         if ub.home_dir not in run_info['fname_xgtrain']:
   645                                             for i in ub.possible_home_dirs:
   646                                                 if i in run_info['fname_xgtrain']:
   647                                                     logged_home_dir = i
   648                             
   649                                             for k in ['fname_xgtrain', 'fname_xgval', 'fname_ytrain', 'fname_yval']:
   650                                                 run_info[k] = run_info[k].replace(logged_home_dir, ub.home_dir)
   651                             
   652                                             if analyze_feature_importance:
   653                                                 for k in ['feature_imp_fname_template', 'top_feature_fname']:
   654                                                     run_info[k] = run_info[k].replace(logged_home_dir, ub.home_dir)
   655                             
   656                                         ub.log('Loading xgtrain data {} ...'.format(run_info['fname_xgtrain']))
   657                                         xgtrain = xgb.DMatrix(run_info['fname_xgtrain'])
   658                             
   659                                         ub.log('Loading xgval data {} ...'.format(run_info['fname_xgval']))
   660                                         xgval = xgb.DMatrix(run_info['fname_xgval'])
   661                             
   662                                         ub.log('Loading ytrain data {} ...'.format(run_info['fname_ytrain']))
   663                                         y_train = np.load(run_info['fname_ytrain'])
   664                             
   665                                         ub.log('Loading yval data {} ...'.format(run_info['fname_yval']))
   666                                         y_val = np.load(run_info['fname_yval'])
   667                             
   668  39490.3 MiB      0.0 MiB           prior = run_info['prior']
   669  39490.3 MiB      0.0 MiB           postfix_train = run_info['postfix_train']
   670                             
   671  39490.3 MiB      0.0 MiB           if xgb_params is None:
   672                                         xgb_params = get_params(bases_core=prior)
   673                             
   674  39490.3 MiB      0.0 MiB           xgb_params['base_score'] = prior  # n_positive / n_total
   675                                     # xgb_params['scale_pos_weight'] = (1.0 - prior) / prior
   676  39490.3 MiB      0.0 MiB           run_info['xgb_params'] = xgb_params
   677  39490.3 MiB      0.0 MiB           ub.log('Get xgb_params')
   678  39490.3 MiB      0.0 MiB           print xgb_params
   679                             
   680  39490.3 MiB      0.0 MiB           xgb_num_rounds = N_rounds
   681  39490.3 MiB      0.0 MiB           run_info['xgb_num_rounds'] = xgb_num_rounds
   682  39490.3 MiB      0.0 MiB           print 'xgb_num_rounds', xgb_num_rounds
   683  39490.3 MiB      0.0 MiB           if cv:
   684                                         ub.log('Running cross validation...')
   685                                         eval_hist = xgb.cv(xgb_params, xgtrain, num_boost_round=xgb_num_rounds,
   686                                                            early_stopping_rounds=early_stop_rounds,
   687                                                            feval=ub.mcc_eval, maximize=True,
   688                                                            verbose_eval=1, show_stdv=True, nfold=3, seed=0, stratified=True)
   689                                         print eval_hist
   690                                         eval_hist_fname = os.path.join(ub.output_dir, 'cv_eval_history_{}.csv'.format(postfix_train))
   691                                         if not compile_data:
   692                                             eval_hist_fname = eval_hist_fname.replace('.csv', '_{}.csv'.format(datetime_str))
   693                             
   694                                         run_info['eval_hist_fname'] = eval_hist_fname
   695                                         eval_hist.to_csv(eval_hist_fname)
   696                             
   697                                         run_info['cv_score_test'] = eval_hist['test-MCC-mean'].max()
   698                                         run_info['cv_score_train'] = eval_hist['train-MCC-mean'].max()
   699                             
   700                                     if 1:
   701  39490.3 MiB      0.0 MiB               ub.log('Running training...')
   702  39490.3 MiB      0.0 MiB               watchlist = [(xgtrain, 'train'), (xgval, 'eval')]
   703  39490.3 MiB      0.0 MiB               model = xgb.train(xgb_params, xgtrain, num_boost_round=xgb_num_rounds,
   704  39490.3 MiB      0.0 MiB                                 early_stopping_rounds=early_stop_rounds,
   705  39490.3 MiB      0.0 MiB                                 feval=ub.mcc_eval, maximize=True,
   706  48501.9 MiB   9011.6 MiB                                 evals=watchlist, verbose_eval=True)
   707                             
   708  48501.9 MiB      0.0 MiB               model_fname = os.path.join(ub.output_dir, 'xbg_{}.model'.format(postfix_train))
   709  48501.9 MiB      0.0 MiB               if not compile_data:
   710                                             model_fname = model_fname.replace('.model', '_{}.model'.format(datetime_str))
   711  48501.9 MiB      0.0 MiB               ub.log('Saving model: {}...'.format(model_fname))
   712  48501.9 MiB      0.0 MiB               model.save_model(model_fname)
   713  48501.9 MiB      0.0 MiB               model.dump_model(model_fname + '.raw.txt')
   714  48501.9 MiB      0.0 MiB               run_info['model_fname'] = model_fname
   715                             
   716  48501.9 MiB      0.0 MiB               ntree_limit = model.best_iteration + 1
   717                             
   718  48501.9 MiB      0.0 MiB               ub.log('Predictions on xgtrain...', 'highlight')
   719  48501.9 MiB      0.0 MiB               predictions = model.predict(xgtrain, ntree_limit=ntree_limit)
   720                             
   721  48487.9 MiB    -14.0 MiB               best_proba, best_mcc, y_pred = ub.eval_mcc(y_train, predictions, True)
   722  48498.1 MiB     10.3 MiB               mcc_official = matthews_corrcoef(y_train, y_pred)
   723  48498.1 MiB      0.0 MiB               print 'ntree limit:', ntree_limit
   724  48498.1 MiB      0.0 MiB               print 'best_mcc:', best_mcc
   725  48498.1 MiB      0.0 MiB               print 'best_proba:', best_proba
   726  48498.1 MiB      0.0 MiB               print 'matthews_corroef', mcc_official
   727                             
   728  48498.1 MiB      0.0 MiB               run_info['ntree_limit_train'] = ntree_limit
   729  48498.1 MiB      0.0 MiB               run_info['best_mcc_train'] = best_mcc
   730  48498.1 MiB      0.0 MiB               run_info['best_proba_train'] = best_proba
   731  48498.1 MiB      0.0 MiB               run_info['mcc_official_train'] = mcc_official
   732                             
   733  48498.1 MiB      0.0 MiB               ub.log('Predictions on xgval...', 'highlight')
   734  48498.1 MiB      0.0 MiB               predictions = model.predict(xgval, ntree_limit=ntree_limit)
   735                             
   736  48498.1 MiB      0.0 MiB               best_proba, best_mcc, y_pred = ub.eval_mcc(y_val, predictions, True)
   737  48498.1 MiB      0.0 MiB               mcc_official = matthews_corrcoef(y_val, y_pred)
   738  48498.1 MiB      0.0 MiB               print 'ntree limit:', ntree_limit
   739  48498.1 MiB      0.0 MiB               print 'best_mcc:', best_mcc
   740  48498.1 MiB      0.0 MiB               print 'best_proba:', best_proba
   741  48498.1 MiB      0.0 MiB               print 'matthews_corroef', mcc_official
   742                             
   743  48498.1 MiB      0.0 MiB               run_info['ntree_limit_val'] = ntree_limit
   744  48498.1 MiB      0.0 MiB               run_info['best_mcc_val'] = best_mcc
   745  48498.1 MiB      0.0 MiB               run_info['best_proba_val'] = best_proba
   746  48498.1 MiB      0.0 MiB               run_info['mcc_official_val'] = mcc_official
   747                             
   748  48498.1 MiB      0.0 MiB               if analyze_feature_importance:
   749  48498.1 MiB      0.0 MiB                   ub.log('Analyzing feature importance...')
   750  48498.1 MiB      0.0 MiB                   feature_imp_fname_template = run_info['feature_imp_fname_template']
   751  48498.1 MiB      0.0 MiB                   top_features_fname = run_info['top_features_fname']
   752  48498.1 MiB      0.0 MiB                   feature_imp_fname = feature_imp_fname_template.format(postfix_train)
   753  48498.1 MiB      0.0 MiB                   imp = model.get_fscore()
   754  48498.1 MiB      0.0 MiB                   imp = sorted(imp.items(), key=operator.itemgetter(1))
   755  48498.5 MiB      0.3 MiB                   imp_df = pd.DataFrame(imp, columns=['feature', 'fscore'])
   756  48499.9 MiB      1.4 MiB                   imp_df['fscore'] = imp_df['fscore'] / imp_df['fscore'].sum()
   757                             
   758  48499.9 MiB      0.0 MiB                   ub.log('Output result csv to {}...'.format(feature_imp_fname + '.csv'))
   759  48499.9 MiB      0.0 MiB                   imp_df.to_csv(feature_imp_fname + '.csv')
   760                             
   761  48505.7 MiB      5.8 MiB                   plt.figure()
   762  48510.0 MiB      4.3 MiB                   imp_df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(6, 10))
   763  48510.0 MiB      0.0 MiB                   plt.title('XGBoost Feature Importance @ {}'.format(postfix_train))
   764  48510.0 MiB      0.0 MiB                   plt.xlabel('relative importance')
   765  48491.5 MiB    -18.5 MiB                   plt.gcf().savefig(feature_imp_fname + '.png', bbox_inches='tight')
   766                             
   767  48491.7 MiB      0.2 MiB                   feature_lists = glob.glob(feature_imp_fname_template.replace('{}', '*.csv'))
   768  48491.7 MiB      0.0 MiB                   ub.log('Aggregating previous analysis results...')
   769  48491.7 MiB      0.0 MiB                   print feature_lists
   770  48491.7 MiB      0.0 MiB                   features_df = None
   771  48491.7 MiB      0.0 MiB                   if feature_lists:
   772  48493.3 MiB      1.6 MiB                       for f_l in feature_lists:
   773  48493.3 MiB      0.0 MiB                           tmp_df = pd.read_csv(f_l, index_col=0)
   774  48493.3 MiB      0.0 MiB                           if features_df is None:
   775  48491.7 MiB     -1.6 MiB                               features_df = tmp_df
   776                                                     else:
   777  48493.3 MiB      1.6 MiB                               features_df = pd.concat([features_df, tmp_df], ignore_index=True)
   778                             
   779  48493.3 MiB      0.0 MiB                   f_df = features_df.groupby(['feature']).mean().reset_index()
   780  48493.3 MiB      0.0 MiB                   f_df['overall'] = True
   781  48493.3 MiB      0.0 MiB                   imp_df['overall'] = False
   782  48493.6 MiB      0.3 MiB                   merged_df = pd.concat([imp_df, f_df]).sort_values(by=['overall', 'fscore'], ascending=False)
   783  48493.6 MiB      0.0 MiB                   sns_plot = sns.factorplot(y='feature', x='fscore', data=merged_df, hue='overall', kind='bar',
   784  48533.2 MiB     39.6 MiB                                             hue_order=[True, False], size=20, aspect=0.5)
   785  48517.2 MiB    -15.9 MiB                   sns_plot.savefig(feature_imp_fname + '_overall.png', bbox_inches='tight')
   786                             
   787  48517.2 MiB      0.0 MiB                   ub.log('Output overall result csv to {}...'.format(top_features_fname))
   788  48517.2 MiB      0.0 MiB                   with open(top_features_fname, 'w') as tf:
   789  48517.2 MiB      0.0 MiB                       tf.write('\n'.join(list(set(merged_df.feature.values))))
   790                             
   791  48517.2 MiB      0.0 MiB                   merged_df.to_csv(top_features_fname.replace('.txt', '_df.csv'), index=False)
   792                             
   793                             
   794                                             # json has trouble serializing np.float32
   795                                             # with open(run_info_fname, 'w') as fp:
   796                                             #    json.dump(run_info, fp)
   797                             
   798  48517.2 MiB      0.0 MiB       if make_submission:
   799                                     assert (run_info_fname is not None)
   800                             
   801                                     if not train_model and not compile_data:
   802                                         ub.log('(make_submission) Loading run info from {} ...'.format(run_info_fname))
   803                                         with open(run_info_fname, 'r') as fp:
   804                                             run_info = eval(fp.read())
   805                                         print json.dumps(run_info, indent=2)
   806                             
   807                                     if ub.home_dir not in run_info['model_fname']:
   808                                         for i in ub.possible_home_dirs:
   809                                             if i in run_info['model_fname']:
   810                                                 logged_home_dir = i
   811                             
   812                                     for k in ['fname_xgtest', 'model_fname']:
   813                                         if ub.home_dir not in run_info[k]:
   814                                             for i in ub.possible_home_dirs:
   815                                                 if i in run_info[k]:
   816                                                     run_info[k] = run_info[k].replace(i, ub.home_dir)
   817                             
   818                                     if not train_model:
   819                                         model = xgb.Booster()
   820                                         ub.log('Loading model {} ...'.format(run_info['model_fname']))
   821                                         model.load_model(run_info['model_fname'])
   822                             
   823                                     if not compile_data:
   824                                         ub.log('Loading xgtest data {} ...'.format(run_info['fname_xgtest']))
   825                                         xgtest = xgb.DMatrix(run_info['fname_xgtest'])
   826                             
   827                                     ub.log('XGB making predictions...')
   828                             
   829                                     postfix_train = run_info['postfix_train']
   830                             
   831                                     ypred = model.predict(xgtest, ntree_limit=run_info['ntree_limit_train'])
   832                                     nrows = len(ypred)
   833                             
   834                                     sample = pd.read_csv(os.path.join(ub.data_dir, 'sample_submission.csv'), nrows=nrows)
   835                                     sample['Response'] = ypred
   836                                     fname_output = os.path.join(ub.output_dir, "sub_xgboost_{}_prob.csv".format(postfix_train))
   837                                     if not compile_data:
   838                                         fname_output = fname_output.replace('.csv', '_{}.csv'.format(datetime_str))
   839                                     ub.log('Writing output file (raw proba) {} ...'.format(fname_output))
   840                                     sample.to_csv(fname_output, index=False)
   841                             
   842                                     best_proba = (run_info['best_proba_train'] + run_info['best_proba_val']) / 2.0
   843                                     ub.log('Using threshold: best_proba == {}'.format(best_proba))
   844                                     sample['Response'] = (ypred > best_proba).astype(int)
   845                                     fname_output = os.path.join(ub.output_dir, "sub_xgboost_{}.csv".format(postfix_train))
   846                                     if not compile_data:
   847                                         fname_output = fname_output.replace('.csv', '_{}.csv'.format(datetime_str))
   848                                     ub.log('Writing output file {} ...'.format(fname_output))
   849                                     sample.to_csv(fname_output, index=False)
   850                             
   851  48517.2 MiB      0.0 MiB       if compile_data or train_model:
   852  48517.2 MiB      0.0 MiB           if compile_data:
   853  48517.2 MiB      0.0 MiB               if run_info_fname is not None:
   854                                             ub.log('Ignore input run_info_fname {}'.format(run_info_fname))
   855  48517.2 MiB      0.0 MiB               run_info_fname = os.path.join(ub.output_dir, 'run_info_{}.txt'.format(postfix_train))
   856                                     # else run_info_fname is an input parameter
   857  48517.2 MiB      0.0 MiB           ub.log('Saving run_info into {}'.format(run_info_fname))
   858  48517.5 MiB      0.2 MiB           print pd.Series(run_info)
   859  48517.5 MiB      0.0 MiB           with open(run_info_fname, 'w') as fp:
   860  48517.5 MiB      0.0 MiB               fp.write(str(run_info))
   861                             
   862  48517.5 MiB      0.0 MiB       return run_info_fname


