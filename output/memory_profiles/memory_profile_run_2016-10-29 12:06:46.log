Filename: main_bosch.py

Line #    Mem usage    Increment   Line Contents
================================================
   311    160.9 MiB      0.0 MiB   @profile(stream=f_mem)
   312                             def main(run_info_fname=None,
   313                                      compile_data=False,
   314                                      train_model=False,
   315                                      make_submission=False,
   316                                      N_start=None,
   317                                      N_files_train=1,
   318                                      N_files_test=1,
   319                                      feature_down_select=False,
   320                                      N_features=700,
   321                                      analyze_feature_importance=False,
   322                                      cv=False,
   323                                      # if True running cross validation if False, run single model training session and importance analysis
   324                                      early_stop_rounds=50,
   325                                      N_rounds=1000,
   326                                      testsize=0.1,
   327                                      xgb_params=None
   328                                      ):
   329    160.9 MiB      0.0 MiB       datetime_str = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
   330                             
   331    160.9 MiB      0.0 MiB       if compile_data:
   332    160.9 MiB      0.0 MiB           run_info = dict()
   333    160.9 MiB      0.0 MiB           N_splits = ub.N_split
   334    160.9 MiB      0.0 MiB           if N_files_train > N_splits:
   335                                         N_files_train = N_splits
   336    160.9 MiB      0.0 MiB           if N_files_test > N_splits:
   337                                         N_files_test = N_splits
   338                             
   339    160.9 MiB      0.0 MiB           if analyze_feature_importance and feature_down_select:
   340                                         assert 0
   341                             
   342    160.9 MiB      0.0 MiB           run_info['N_splits'] = N_splits
   343    160.9 MiB      0.0 MiB           run_info['N_files_train'] = N_files_train
   344    160.9 MiB      0.0 MiB           run_info['N_files_test'] = N_files_test
   345    160.9 MiB      0.0 MiB           run_info['feature_down_select'] = feature_down_select
   346    160.9 MiB      0.0 MiB           run_info['N_features'] = N_features
   347    160.9 MiB      0.0 MiB           run_info['cv'] = cv
   348    160.9 MiB      0.0 MiB           run_info['analyze_feature_importance'] = analyze_feature_importance
   349    160.9 MiB      0.0 MiB           run_info['early_stop_rounds'] = early_stop_rounds
   350                             
   351    160.9 MiB      0.0 MiB           df_train, n_start = load_data(load_test=False, N_start=N_start, N_read=N_files_train, N_split=N_splits,
   352    160.9 MiB      0.0 MiB                                         shuffle=False,
   353   8938.6 MiB   8777.6 MiB                                         feature_down_select=feature_down_select, N_features=N_features)
   354   8938.6 MiB      0.0 MiB           df_test, _ = load_data(load_test=True, N_start=n_start, N_read=N_files_test, N_split=N_splits, shuffle=False,
   355  18112.8 MiB   9174.2 MiB                                  feature_down_select=feature_down_select, N_features=N_features)
   356                             
   357  18112.8 MiB      0.0 MiB           ub.log('generating id diff columns based on various dates columns')
   358  18112.8 MiB      0.0 MiB           dates_cols = [x for x in list(df_train.columns) if ('start_date' in x or 'end_date' in x) and ('rank' not in x)]
   359                             
   360                                     # print dates_cols
   361                             
   362  22268.7 MiB   4155.8 MiB           df_datesort = pd.concat([df_train[['Id'] + dates_cols], df_test[['Id'] + dates_cols]],
   363  22269.3 MiB      0.6 MiB                                   ignore_index=True)
   364  22944.3 MiB    675.0 MiB           gc.collect()
   365                             
   366  28841.7 MiB   5897.4 MiB           for c in dates_cols:
   367                                         # print c
   368  28773.8 MiB    -67.9 MiB               df_datesort.sort_values(by=[c, 'Id'], inplace=True)
   369  28773.8 MiB      0.0 MiB               df_datesort[c + '_id_diff'] = df_datesort['Id'].diff().fillna(999999).astype(int)
   370  28773.8 MiB      0.0 MiB               df_datesort[c + '_id_diff_reverse'] = df_datesort['Id'].iloc[::-1].diff().fillna(999999).astype(int)
   371                                         df_datesort[c + '_id_diff_magic'] = \
   372  28773.8 MiB      0.0 MiB                   1 + 2 * (df_datesort[c + '_id_diff'] > 1) + 1 * (df_datesort[c + '_id_diff_reverse'] < -1)
   373                             
   374  28841.7 MiB     67.9 MiB               df_datesort.drop([c], axis=1, inplace=True)
   375                             
   376  24786.1 MiB  -4055.6 MiB           df_datesort.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_datesort_debug.csv'))
   377                             
   378  21383.8 MiB  -3402.4 MiB           gc.collect()
   379  28359.6 MiB   6975.9 MiB           df_train = df_train.merge(df_datesort, on='Id')
   380  28375.0 MiB     15.4 MiB           df_train.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_train_debug.csv'))
   381                             
   382  21168.2 MiB  -7206.7 MiB           gc.collect()
   383  27892.9 MiB   6724.7 MiB           df_test = df_test.merge(df_datesort, on='Id')
   384  27930.2 MiB     37.3 MiB           df_test.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_test_debug.csv'))
   385                             
   386  22433.3 MiB  -5496.9 MiB           df_test['Response'] = 0
   387                             
   388  22433.5 MiB      0.2 MiB           print df_train.shape
   389  22433.5 MiB      0.0 MiB           print df_test.shape
   390  21386.6 MiB  -1046.9 MiB           gc.collect()
   391                             
   392                                     # if N_files_train == N_splits:
   393                                     #     split_data(df_train,
   394                                     #                output_fname_template=os.path.join(ub.processed_data_dir, 'df_train_preprocessed_part{}.csv'))
   395                                     # if N_files_test == N_splits:
   396                                     #     split_data(df_test,
   397                                     #                output_fname_template=os.path.join(ub.processed_data_dir, 'df_test_preprocessed_part{}.csv'))
   398                             
   399  21386.6 MiB      0.0 MiB           fillna = True
   400  21386.6 MiB      0.0 MiB           run_info['fillna'] = fillna
   401  21386.6 MiB      0.0 MiB           if fillna:
   402  21386.6 MiB      0.0 MiB               ub.log('Filling na...')
   403  22374.9 MiB    988.3 MiB               for df in [df_train, df_test]:
   404  23700.6 MiB   1325.7 MiB                   cols_full_flag = df.isnull().any()
   405  23701.6 MiB      1.0 MiB                   non_full_cols = list(cols_full_flag[cols_full_flag].index)
   406  23701.6 MiB      0.0 MiB                   print 'Non-full columns: {}'.format(len(non_full_cols))
   407                                             # print non_full_cols
   408                             
   409                                             if 1:
   410  23703.6 MiB      2.0 MiB                       df.fillna(-999999, inplace=True)
   411                                             else:
   412                                                 # print df.PersonalField7.unique()
   413                                                 for c in non_full_cols:
   414                                                     if len(df[c].unique()) > 2:
   415                                                         most_frequent_items = df[c].value_counts().idxmax()
   416                                                         print c, most_frequent_items
   417                                                         df[c].fillna(value=most_frequent_items, inplace=True)
   418                                                     else:  # if it is only a pair of value [somthing, nan] then fill in "missing"
   419                                                         df[c].fillna(value='missing', inplace=True)
   420                                                         print c, df[c].unique()
   421                             
   422  23703.6 MiB      0.0 MiB                   cols_full_flag = df.isnull().any()
   423  23703.6 MiB      0.0 MiB                   non_full_cols = list(cols_full_flag[cols_full_flag].index)
   424  23703.6 MiB      0.0 MiB                   print 'Non-full columns: {}'.format(len(non_full_cols))
   425                             
   426  23703.6 MiB      0.0 MiB                   le = LabelEncoder()
   427  23704.4 MiB      0.8 MiB                   obj_cols = df.select_dtypes(include=['object']).columns
   428                                             # print 'Obj columns: ', list(obj_cols)
   429  23704.4 MiB      0.0 MiB                   for col in obj_cols:
   430  23703.2 MiB     -1.1 MiB                       df[col] = le.fit_transform(df[col])
   431                             
   432  20629.7 MiB  -3073.5 MiB               df_train.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_train_cleanup_debug.csv'))
   433  20629.7 MiB      0.0 MiB               df_test.head(n=1000).to_csv(os.path.join(ub.data_dir, 'df_train_cleanup_debug.csv'))
   434                             
   435  20629.7 MiB      0.0 MiB           ub.log('Dropping Id and Response columns...')
   436  20629.7 MiB      0.0 MiB           columns_to_drop = ['Id', 'Response']
   437  22787.6 MiB   2157.8 MiB           shuffle_col = df_train[['Id']].copy()
   438  22787.6 MiB      0.0 MiB           shuffle_col['Id'] = np.random.randn(len(shuffle_col))
   439                             
   440  22787.6 MiB      0.0 MiB           y_total_df = df_train['Response']
   441  22787.6 MiB      0.0 MiB           y_total = df_train['Response'].values
   442  25020.9 MiB   2233.3 MiB           df_train.drop(columns_to_drop, axis=1, inplace=True)
   443  24246.8 MiB   -774.0 MiB           df_test.drop(columns_to_drop, axis=1, inplace=True)
   444                             
   445  24246.8 MiB      0.0 MiB           print df_train.shape
   446  24246.8 MiB      0.0 MiB           print df_test.shape
   447  24247.2 MiB      0.3 MiB           prior = np.sum(y_total) / (1. * len(y_total))
   448  24247.2 MiB      0.0 MiB           print 'prior: {}'.format(prior)
   449  24247.2 MiB      0.0 MiB           run_info['prior'] = prior
   450                             
   451  26040.6 MiB   1793.4 MiB           gc.collect()
   452                             
   453  26040.6 MiB      0.0 MiB           feature_imp_fname_template = os.path.join(ub.output_dir, 'feature_importance_xgb_{}')
   454  26040.6 MiB      0.0 MiB           run_info['feature_imp_fname_template'] = feature_imp_fname_template
   455  26040.6 MiB      0.0 MiB           top_features_fname = feature_imp_fname_template.format('accumu_list.txt')
   456  26040.6 MiB      0.0 MiB           run_info['top_features_fname'] = top_features_fname
   457                             
   458                                     # if feature_down_select:
   459                                     #     ub.log('Feature down selected based on {}...'.format(top_features_fname))
   460                                     #     #todo may need to set a maxN for the number of features to use
   461                                     #
   462                                     #     with open(top_features_fname, 'r') as tf:
   463                                     #         selected_cols = [x.strip() for x in tf.readlines()]
   464                                     #     df_train = df_train[selected_cols]
   465                                     #     df_test = df_test[selected_cols]
   466                                     #     print df_train.shape
   467                                     #     print df_test.shape
   468                                     #     print df_train.columns
   469                             
   470  26040.6 MiB      0.0 MiB           feature_names = list(df_train.columns)
   471                             
   472  26040.6 MiB      0.0 MiB           postfix_train = '{}_{}of{}'.format(datetime_str, N_files_train, N_splits)
   473  26040.6 MiB      0.0 MiB           postfix_test = '{}_{}of{}'.format(datetime_str, N_files_test, N_splits)
   474                             
   475  26040.6 MiB      0.0 MiB           run_info['postfix_train'] = postfix_train
   476  26040.6 MiB      0.0 MiB           run_info['postfix_test'] = postfix_test
   477                             
   478  26040.6 MiB      0.0 MiB           run_info['testsize'] = testsize
   479                             
   480  26040.6 MiB      0.0 MiB           train_test_split_method = 1
   481                             
   482  26040.6 MiB      0.0 MiB           ub.log('Train/val split using testsize={}, split_method={}'.format(testsize, train_test_split_method))
   483  26040.6 MiB      0.0 MiB           if train_test_split_method == 1:
   484  26043.0 MiB      2.4 MiB               train_idx = shuffle_col[shuffle_col['Id'] > testsize].index
   485  26043.0 MiB      0.0 MiB               val_idx = shuffle_col[shuffle_col['Id'] <= testsize].index
   486  26043.0 MiB      0.0 MiB               ub.log('Done shuffling...')
   487  26043.0 MiB      0.0 MiB               print 'len of train_idx', len(train_idx)
   488  26043.0 MiB      0.0 MiB               print 'len of val_idx', len(val_idx)
   489  26043.4 MiB      0.4 MiB               y_train = y_total_df.loc[train_idx].values
   490  26043.4 MiB      0.0 MiB               y_val = y_total_df.loc[val_idx].values
   491                             
   492  23933.9 MiB  -2109.4 MiB               xgtrain = xgb.DMatrix(df_train.loc[train_idx].values, y_train, feature_names=feature_names)
   493  23934.6 MiB      0.6 MiB               ub.log('Assembled xgtrain')
   494  20109.2 MiB  -3825.3 MiB               xgval = xgb.DMatrix(df_train.loc[val_idx].values, y_val, feature_names=feature_names)
   495  20109.2 MiB      0.0 MiB               ub.log('Assembled xgval')
   496  20109.2 MiB      0.0 MiB               del df_train
   497  20109.2 MiB      0.0 MiB               ub.log('Deleted df_train')
   498  18664.0 MiB  -1445.3 MiB               gc.collect()
   499                                     else:
   500                                         x_train, x_val, y_train, y_val = train_test_split(df_train.values, y_total, test_size=testsize)
   501                                         ub.log('Done shuffling...')
   502                                         print x_train.shape
   503                                         print x_val.shape
   504                                         del df_train
   505                                         gc.collect()
   506                                         ub.log('Deleted df_train')
   507                             
   508                                         xgtrain = xgb.DMatrix(x_train, y_train, feature_names=feature_names)
   509                                         ub.log('Assembled xgtrain')
   510                                         xgval = xgb.DMatrix(x_val, y_val, feature_names=feature_names)
   511                                         ub.log('Assembled xgval')
   512                                         del x_train
   513                                         del x_val
   514                                         gc.collect()
   515                             
   516  18664.0 MiB      0.0 MiB           fname_xgtrain = os.path.join(ub.processed_data_dir, 'xgtrain_{}.buffer'.format(postfix_train))
   517  19235.1 MiB    571.1 MiB           xgtrain.save_binary(fname_xgtrain)
   518  19235.1 MiB      0.0 MiB           ub.log('Saved {}'.format(fname_xgtrain))
   519                             
   520  19235.1 MiB      0.0 MiB           fname_xgval = os.path.join(ub.processed_data_dir, 'xgval_{}.buffer'.format(postfix_train))
   521  19235.2 MiB      0.1 MiB           xgval.save_binary(fname_xgval)
   522  19235.2 MiB      0.0 MiB           ub.log('Saved {}'.format(fname_xgval))
   523                             
   524  18431.3 MiB   -803.9 MiB           xgtest = xgb.DMatrix(df_test.values, feature_names=feature_names)
   525  18431.7 MiB      0.3 MiB           ub.log('Assembled xgtest')
   526  18431.7 MiB      0.0 MiB           fname_xgtest = os.path.join(ub.processed_data_dir, 'xgtest_{}.buffer'.format(postfix_test))
   527  18456.7 MiB     25.1 MiB           xgtest.save_binary(fname_xgtest)
   528  18456.7 MiB      0.0 MiB           ub.log('Saved {}'.format(fname_xgtest))
   529                             
   530  18456.7 MiB      0.0 MiB           del df_test
   531  18472.7 MiB     16.0 MiB           gc.collect()
   532  18472.7 MiB      0.0 MiB           ub.log('Deleted df_test')
   533                             
   534  18472.7 MiB      0.0 MiB           print 'train and val set sizes'
   535  18472.7 MiB      0.0 MiB           print xgtrain.num_row(), xgtrain.num_col()
   536  18472.7 MiB      0.0 MiB           print xgval.num_row(), xgval.num_col()
   537                             
   538  18472.7 MiB      0.0 MiB           run_info['fname_xgtrain'] = fname_xgtrain
   539  18472.7 MiB      0.0 MiB           run_info['fname_xgval'] = fname_xgval
   540  18472.7 MiB      0.0 MiB           run_info['fname_xgtest'] = fname_xgtest
   541                             
   542  18472.7 MiB      0.0 MiB           fname_ytrain = os.path.join(ub.processed_data_dir, 'ytrain_{}.npy'.format(postfix_train))
   543  18472.7 MiB      0.0 MiB           fname_yval = os.path.join(ub.processed_data_dir, 'yval_{}.npy'.format(postfix_train))
   544                             
   545  18473.7 MiB      1.0 MiB           np.save(fname_ytrain, y_train)
   546  18473.7 MiB      0.0 MiB           ub.log('Saved ' + fname_ytrain)
   547                             
   548  18473.7 MiB      0.0 MiB           np.save(fname_yval, y_val)
   549  18473.7 MiB      0.0 MiB           ub.log('Saved ' + fname_yval)
   550                             
   551  18473.7 MiB      0.0 MiB           run_info['fname_ytrain'] = fname_ytrain
   552  18473.7 MiB      0.0 MiB           run_info['fname_yval'] = fname_yval
   553                             
   554  18473.7 MiB      0.0 MiB       if train_model:
   555  18473.7 MiB      0.0 MiB           assert compile_data or (run_info_fname is not None)
   556                             
   557  18473.7 MiB      0.0 MiB           if not compile_data:
   558                                         ub.log('(train_model) Loading run info from {} ...'.format(run_info_fname))
   559                                         with open(run_info_fname, 'r') as fp:
   560                                             run_info = eval(fp.read())
   561                                         print json.dumps(run_info, indent=2)
   562                             
   563                                         run_info_fname = run_info_fname.replace('.txt', '_{}.txt'.format(datetime_str))
   564                             
   565                                         logged_home_dir = None
   566                                         if ub.home_dir not in run_info['fname_xgtrain']:
   567                                             for i in ub.possible_home_dirs:
   568                                                 if i in run_info['fname_xgtrain']:
   569                                                     logged_home_dir = i
   570                             
   571                                             for k in ['fname_xgtrain', 'fname_xgval', 'fname_ytrain', 'fname_yval']:
   572                                                 run_info[k] = run_info[k].replace(logged_home_dir, ub.home_dir)
   573                             
   574                                             if analyze_feature_importance:
   575                                                 for k in ['feature_imp_fname_template', 'top_feature_fname']:
   576                                                     run_info[k] = run_info[k].replace(logged_home_dir, ub.home_dir)
   577                             
   578                                         ub.log('Loading xgtrain data {} ...'.format(run_info['fname_xgtrain']))
   579                                         xgtrain = xgb.DMatrix(run_info['fname_xgtrain'])
   580                             
   581                                         ub.log('Loading xgval data {} ...'.format(run_info['fname_xgval']))
   582                                         xgval = xgb.DMatrix(run_info['fname_xgval'])
   583                             
   584                                         ub.log('Loading ytrain data {} ...'.format(run_info['fname_ytrain']))
   585                                         y_train = np.load(run_info['fname_ytrain'])
   586                             
   587                                         ub.log('Loading yval data {} ...'.format(run_info['fname_yval']))
   588                                         y_val = np.load(run_info['fname_yval'])
   589                             
   590  18473.7 MiB      0.0 MiB           prior = run_info['prior']
   591  18473.7 MiB      0.0 MiB           postfix_train = run_info['postfix_train']
   592                             
   593  18473.7 MiB      0.0 MiB           run_info['cv'] = cv
   594  18473.7 MiB      0.0 MiB           run_info['analyze_feature_importance'] = analyze_feature_importance
   595  18473.7 MiB      0.0 MiB           run_info['early_stop_rounds'] = early_stop_rounds
   596                             
   597  18473.7 MiB      0.0 MiB           if xgb_params is None:
   598                                         xgb_params = get_params(bases_core=prior)
   599                             
   600  18473.7 MiB      0.0 MiB           xgb_params['base_score'] = prior  # n_positive / n_total
   601                                     # xgb_params['scale_pos_weight'] = (1.0 - prior) / prior
   602  18473.7 MiB      0.0 MiB           run_info['xgb_params'] = xgb_params
   603  18473.7 MiB      0.0 MiB           ub.log('Get xgb_params')
   604  18473.7 MiB      0.0 MiB           print xgb_params
   605                             
   606  18473.7 MiB      0.0 MiB           xgb_num_rounds = N_rounds
   607  18473.7 MiB      0.0 MiB           run_info['xgb_num_rounds'] = xgb_num_rounds
   608  18473.7 MiB      0.0 MiB           print 'xgb_num_rounds', xgb_num_rounds
   609  18473.7 MiB      0.0 MiB           if cv:
   610                                         ub.log('Running cross validation...')
   611                                         eval_hist = xgb.cv(xgb_params, xgtrain, num_boost_round=xgb_num_rounds,
   612                                                            early_stopping_rounds=early_stop_rounds,
   613                                                            feval=ub.mcc_eval, maximize=True,
   614                                                            verbose_eval=1, show_stdv=True, nfold=3, seed=0, stratified=True)
   615                                         print eval_hist
   616                                         eval_hist_fname = os.path.join(ub.output_dir, 'cv_eval_history_{}.csv'.format(postfix_train))
   617                                         if not compile_data:
   618                                             eval_hist_fname = eval_hist_fname.replace('.csv', '_{}.csv'.format(datetime_str))
   619                             
   620                                         run_info['eval_hist_fname'] = eval_hist_fname
   621                                         eval_hist.to_csv(eval_hist_fname)
   622                             
   623                                         run_info['cv_score_test'] = eval_hist['test-MCC-mean'].max()
   624                                         run_info['cv_score_train'] = eval_hist['train-MCC-mean'].max()
   625                             
   626                                     if 1:
   627  18473.7 MiB      0.0 MiB               ub.log('Running training...')
   628  18473.7 MiB      0.0 MiB               watchlist = [(xgtrain, 'train'), (xgval, 'eval')]
   629  18473.7 MiB      0.0 MiB               model = xgb.train(xgb_params, xgtrain, num_boost_round=xgb_num_rounds,
   630  18473.7 MiB      0.0 MiB                                 early_stopping_rounds=early_stop_rounds,
   631  18473.7 MiB      0.0 MiB                                 feval=ub.mcc_eval, maximize=True,
   632  22813.5 MiB   4339.8 MiB                                 evals=watchlist, verbose_eval=True)
   633                             
   634  22813.5 MiB      0.0 MiB               model_fname = os.path.join(ub.output_dir, 'xbg_{}.model'.format(postfix_train))
   635  22813.5 MiB      0.0 MiB               if not compile_data:
   636                                             model_fname = model_fname.replace('.model', '_{}.model'.format(datetime_str))
   637  22813.5 MiB      0.0 MiB               ub.log('Saving model: {}...'.format(model_fname))
   638  22813.5 MiB      0.0 MiB               model.save_model(model_fname)
   639  22814.2 MiB      0.7 MiB               model.dump_model(model_fname + '.raw.txt')
   640  22814.2 MiB      0.0 MiB               run_info['model_fname'] = model_fname
   641                             
   642  22814.2 MiB      0.0 MiB               ntree_limit = model.best_iteration + 1
   643                             
   644  22814.2 MiB      0.0 MiB               ub.log('Predictions on xgtrain...', 'highlight')
   645  22814.2 MiB      0.0 MiB               predictions = model.predict(xgtrain, ntree_limit=ntree_limit)
   646                             
   647  22814.4 MiB      0.2 MiB               best_proba, best_mcc, y_pred = ub.eval_mcc(y_train, predictions, True)
   648  22817.4 MiB      3.0 MiB               mcc_official = matthews_corrcoef(y_train, y_pred)
   649  22817.4 MiB      0.0 MiB               print 'ntree limit:', ntree_limit
   650  22817.4 MiB      0.0 MiB               print 'best_mcc:', best_mcc
   651  22817.4 MiB      0.0 MiB               print 'best_proba:', best_proba
   652  22817.4 MiB      0.0 MiB               print 'matthews_corroef', mcc_official
   653                             
   654  22817.4 MiB      0.0 MiB               run_info['ntree_limit_train'] = ntree_limit
   655  22817.4 MiB      0.0 MiB               run_info['best_mcc_train'] = best_mcc
   656  22817.4 MiB      0.0 MiB               run_info['best_proba_train'] = best_proba
   657  22817.4 MiB      0.0 MiB               run_info['mcc_official_train'] = mcc_official
   658                             
   659  22817.4 MiB      0.0 MiB               ub.log('Predictions on xgval...', 'highlight')
   660  22817.4 MiB      0.0 MiB               predictions = model.predict(xgval, ntree_limit=ntree_limit)
   661                             
   662  22817.4 MiB      0.0 MiB               best_proba, best_mcc, y_pred = ub.eval_mcc(y_val, predictions, True)
   663  22819.5 MiB      2.1 MiB               mcc_official = matthews_corrcoef(y_val, y_pred)
   664  22819.5 MiB      0.0 MiB               print 'ntree limit:', ntree_limit
   665  22819.5 MiB      0.0 MiB               print 'best_mcc:', best_mcc
   666  22819.5 MiB      0.0 MiB               print 'best_proba:', best_proba
   667  22819.5 MiB      0.0 MiB               print 'matthews_corroef', mcc_official
   668                             
   669  22819.5 MiB      0.0 MiB               run_info['ntree_limit_val'] = ntree_limit
   670  22819.5 MiB      0.0 MiB               run_info['best_mcc_val'] = best_mcc
   671  22819.5 MiB      0.0 MiB               run_info['best_proba_val'] = best_proba
   672  22819.5 MiB      0.0 MiB               run_info['mcc_official_val'] = mcc_official
   673                             
   674  22819.5 MiB      0.0 MiB               if analyze_feature_importance:
   675  22819.5 MiB      0.0 MiB                   ub.log('Analyzing feature importance...')
   676  22819.5 MiB      0.0 MiB                   feature_imp_fname_template = run_info['feature_imp_fname_template']
   677  22819.5 MiB      0.0 MiB                   top_features_fname = run_info['top_features_fname']
   678  22819.5 MiB      0.0 MiB                   feature_imp_fname = feature_imp_fname_template.format(postfix_train)
   679  22819.5 MiB      0.0 MiB                   imp = model.get_fscore()
   680  22819.5 MiB      0.0 MiB                   imp = sorted(imp.items(), key=operator.itemgetter(1))
   681  22820.1 MiB      0.6 MiB                   imp_df = pd.DataFrame(imp, columns=['feature', 'fscore'])
   682  22820.9 MiB      0.8 MiB                   imp_df['fscore'] = imp_df['fscore'] / imp_df['fscore'].sum()
   683                             
   684  22820.9 MiB      0.0 MiB                   ub.log('Output result csv to {}...'.format(feature_imp_fname + '.csv'))
   685  22821.4 MiB      0.5 MiB                   imp_df.to_csv(feature_imp_fname + '.csv')
   686                             
   687  22855.2 MiB     33.8 MiB                   plt.figure()
   688  22888.9 MiB     33.6 MiB                   imp_df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(6, 10))
   689  22889.1 MiB      0.2 MiB                   plt.title('XGBoost Feature Importance @ {}'.format(postfix_train))
   690  22889.1 MiB      0.0 MiB                   plt.xlabel('relative importance')
   691  22900.1 MiB     11.0 MiB                   plt.gcf().savefig(feature_imp_fname + '.png', bbox_inches='tight')
   692                             
   693  22900.1 MiB      0.0 MiB                   feature_lists = glob.glob(feature_imp_fname_template.replace('{}', '*.csv'))
   694  22900.1 MiB      0.0 MiB                   ub.log('Aggregating previous analysis results...')
   695  22900.1 MiB      0.0 MiB                   print feature_lists
   696  22900.1 MiB      0.0 MiB                   features_df = None
   697  22900.1 MiB      0.0 MiB                   if feature_lists:
   698  22900.6 MiB      0.5 MiB                       for f_l in feature_lists:
   699  22900.6 MiB      0.0 MiB                           tmp_df = pd.read_csv(f_l, index_col=0)
   700  22900.6 MiB      0.0 MiB                           if features_df is None:
   701  22900.4 MiB     -0.2 MiB                               features_df = tmp_df
   702                                                     else:
   703  22900.6 MiB      0.2 MiB                               features_df = pd.concat([features_df, tmp_df], ignore_index=True)
   704                             
   705  22900.9 MiB      0.3 MiB                   f_df = features_df.groupby(['feature']).mean().reset_index()
   706  22900.9 MiB      0.0 MiB                   f_df['overall'] = True
   707  22900.9 MiB      0.0 MiB                   imp_df['overall'] = False
   708  22900.9 MiB      0.0 MiB                   merged_df = pd.concat([imp_df, f_df]).sort_values(by=['overall', 'fscore'], ascending=False)
   709  22900.9 MiB      0.0 MiB                   sns_plot = sns.factorplot(y='feature', x='fscore', data=merged_df, hue='overall', kind='bar',
   710  23006.7 MiB    105.8 MiB                                             hue_order=[True, False], size=20, aspect=0.5)
   711  23033.4 MiB     26.7 MiB                   sns_plot.savefig(feature_imp_fname + '_overall.png', bbox_inches='tight')
   712                             
   713  23033.4 MiB      0.0 MiB                   ub.log('Output overall result csv to {}...'.format(top_features_fname))
   714  23033.4 MiB      0.0 MiB                   with open(top_features_fname, 'w') as tf:
   715  23033.4 MiB      0.0 MiB                       tf.write('\n'.join(list(set(merged_df.feature.values))))
   716                             
   717  23033.4 MiB      0.0 MiB                   merged_df.to_csv(top_features_fname.replace('.txt', '_df.csv'), index=False)
   718                             
   719                             
   720                                             # json has trouble serializing np.float32
   721                                             # with open(run_info_fname, 'w') as fp:
   722                                             #    json.dump(run_info, fp)
   723                             
   724  23033.4 MiB      0.0 MiB       if make_submission:
   725                                     assert (run_info_fname is not None)
   726                             
   727                                     if not train_model and not compile_data:
   728                                         ub.log('(make_submission) Loading run info from {} ...'.format(run_info_fname))
   729                                         with open(run_info_fname, 'r') as fp:
   730                                             run_info = eval(fp.read())
   731                                         print json.dumps(run_info, indent=2)
   732                             
   733                                     if ub.home_dir not in run_info['model_fname']:
   734                                         for i in ub.possible_home_dirs:
   735                                             if i in run_info['model_fname']:
   736                                                 logged_home_dir = i
   737                             
   738                                     for k in ['fname_xgtest', 'model_fname']:
   739                                         if ub.home_dir not in run_info[k]:
   740                                             for i in ub.possible_home_dirs:
   741                                                 if i in run_info[k]:
   742                                                     run_info[k] = run_info[k].replace(i, ub.home_dir)
   743                             
   744                                     if not train_model:
   745                                         model = xgb.Booster()
   746                                         ub.log('Loading model {} ...'.format(run_info['model_fname']))
   747                                         model.load_model(run_info['model_fname'])
   748                             
   749                                     if not compile_data:
   750                                         ub.log('Loading xgtest data {} ...'.format(run_info['fname_xgtest']))
   751                                         xgtest = xgb.DMatrix(run_info['fname_xgtest'])
   752                             
   753                                     ub.log('XGB making predictions...')
   754                             
   755                                     postfix_train = run_info['postfix_train']
   756                             
   757                                     ypred = model.predict(xgtest, ntree_limit=run_info['ntree_limit_train'])
   758                                     nrows = len(ypred)
   759                             
   760                                     sample = pd.read_csv(os.path.join(ub.data_dir, 'sample_submission.csv'), nrows=nrows)
   761                                     sample['Response'] = ypred
   762                                     fname_output = os.path.join(ub.output_dir, "sub_xgboost_{}_prob.csv".format(postfix_train))
   763                                     if not compile_data:
   764                                         fname_output = fname_output.replace('.csv', '_{}.csv'.format(datetime_str))
   765                                     ub.log('Writing output file (raw proba) {} ...'.format(fname_output))
   766                                     sample.to_csv(fname_output, index=False)
   767                             
   768                                     best_proba = (run_info['best_proba_train'] + run_info['best_proba_val']) / 2.0
   769                                     ub.log('Using threshold: best_proba == {}'.format(best_proba))
   770                                     sample['Response'] = (ypred > best_proba).astype(int)
   771                                     fname_output = os.path.join(ub.output_dir, "sub_xgboost_{}.csv".format(postfix_train))
   772                                     if not compile_data:
   773                                         fname_output = fname_output.replace('.csv', '_{}.csv'.format(datetime_str))
   774                                     ub.log('Writing output file {} ...'.format(fname_output))
   775                                     sample.to_csv(fname_output, index=False)
   776                             
   777  23033.4 MiB      0.0 MiB       if compile_data or train_model:
   778  23033.4 MiB      0.0 MiB           if compile_data:
   779  23033.4 MiB      0.0 MiB               if run_info_fname is not None:
   780                                             ub.log('Ignore input run_info_fname {}'.format(run_info_fname))
   781  23033.4 MiB      0.0 MiB               run_info_fname = os.path.join(ub.output_dir, 'run_info_{}.txt'.format(postfix_train))
   782                                     # else run_info_fname is an input parameter
   783  23033.4 MiB      0.0 MiB           ub.log('Saving run_info into {}'.format(run_info_fname))
   784  23033.4 MiB      0.1 MiB           print pd.Series(run_info)
   785  23033.4 MiB      0.0 MiB           with open(run_info_fname, 'w') as fp:
   786  23033.4 MiB      0.0 MiB               fp.write(str(run_info))
   787                             
   788  23033.4 MiB      0.0 MiB       return run_info_fname


